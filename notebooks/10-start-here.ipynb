{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here\n",
    "\n",
    "This notebook is all about **getting you started doing Reproducible Data Science** , and giving you a **deeper look** at some of the concepts we will cover in this tutorial.\n",
    "\n",
    "## The Bare Minimum\n",
    "You will need:\n",
    "* `cookiecutter` \n",
    "* `conda` (and then `python >= 3.6`)\n",
    "* `make`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation: While we are talking...\n",
    "\n",
    "(These notes are at: https://github.com/hackalog/bus_number/wiki/Getting-Started)\n",
    "\n",
    "1. [Install cookiecutter](https://cookiecutter.readthedocs.io/en/latest/installation.html), then use it to install the `pydata_nyc` branch of `cookiecutter-easydata`:\n",
    "\n",
    "```\n",
    "cookiecutter https://github.com/hackalog/cookiecutter-easydata.git --checkout pydata_nyc\n",
    "```\n",
    "\n",
    "2. Configure a new project. Call it **bus_number**:\n",
    "<pre>\n",
    "project_name [project_name]: <b>bus_number</b>\n",
    "repo_name [bus_number]: <b>↵</b>\n",
    "module_name [src]: <b>↵</b>\n",
    "author_name [Your name (or your organization/company/team)]: <b>Kjell Wooding</b>\n",
    "description [A short description of this project.]: <b>Reproducible Data Science</b>\n",
    "Select open_source_license:\n",
    "1 - MIT\n",
    "2 - BSD-2-Clause\n",
    "3 - Proprietary\n",
    "Choose from 1, 2, 3 [1]: <b>↵</b>\n",
    "s3_bucket [[OPTIONAL] your-bucket-for-syncing-data (do not include 's3://')]: <b>↵</b>\n",
    "aws_profile [default]: <b>↵</b>\n",
    "Select virtualenv:\n",
    "1 - conda\n",
    "2 - virtualenv\n",
    "Choose from 1, 2 [1]: <b>↵</b>\n",
    "Select python_interpreter:\n",
    "1 - python3\n",
    "2 - python\n",
    "Choose from 1, 2 [1]: <b>↵</b>\n",
    "</pre>\n",
    "\n",
    "3. Create your Development Environment\n",
    "```\n",
    "cd bus_number\n",
    "make create_environment\n",
    "conda activate bus_number         # or `source activate bus_number`\n",
    "make requirements\n",
    "git init\n",
    "```\n",
    "That's it! You're ready to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reproducible Data Science Process\n",
    "### How do you spend your \"Data Science\" time?\n",
    "A Typical data science process looks something like this:\n",
    "* Munge: Fetch, process data, do EDA\n",
    "* Science: Train models, Predict, Transform data\n",
    "* Deliver: Analyze, summarize, publish\n",
    "\n",
    "Usually, the reproducible part is in the **science** step only.\n",
    "<img src=\"../references/charts/munge-supervised.png\" alt=\"Typical Data science Process\" width=\"400\" />\n",
    "\n",
    "We're going to try to improve this to a process that is reproducible from start to finish. The flow looks like this:\n",
    "\n",
    "<img src=\"../references/workflow/workflow-cheat-sheet.png\" alt=\"Reproducible Data Science Workflow\" width=\"400\"/>\n",
    "\n",
    "### Makefiles and the Data Flow\n",
    "We use a `Makefile` to organize and invoke the various steps in our Data Science pipeline.\n",
    "You have already used this file when you created your virtual environment in the first place:\n",
    "```\n",
    "make create_environment\n",
    "```\n",
    "Here are some \n",
    "<img src=\"../references/workflow/workflow-cheat-sheet.png\" alt=\"Reproducible Data Science Workflow\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ASIDE: What's my make target doing?\n",
    "If you are ever curious what commands a `make` command will invoke (including any invoked dependencies), use `make -n`, which lists the commands without executing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 test_environment.py\n",
      "conda env update --name bus_number -f environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. && make -n requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a cute self-documenting trick in our makefiles (borrowed from `cookiecutter-datascience`) to make it easy to document the various targets that you add. This documentation is produced when you type a plain `make`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAvailable rules:\u001b[m\n",
      "\n",
      "\u001b[36mclean              \u001b[m Delete all compiled Python files \n",
      "\u001b[36mclean_datasets     \u001b[m Delete all processed datasets \n",
      "\u001b[36mclean_models       \u001b[m Delete all trained models \n",
      "\u001b[36mclean_predictions  \u001b[m Delete all predictions \n",
      "\u001b[36mcreate_environment \u001b[m Set up python interpreter environment \n",
      "\u001b[36mdata               \u001b[m convert raw datasets into fully processed datasets \n",
      "\u001b[36mlint               \u001b[m Lint using flake8 \n",
      "\u001b[36mpredict            \u001b[m predict / transform / run experiments \n",
      "\u001b[36mraw                \u001b[m Fetch, Unpack, and Process raw dataset files \n",
      "\u001b[36mrequirements       \u001b[m Install or update Python Dependencies \n",
      "\u001b[36msummary            \u001b[m Convert predictions / transforms / experiments into output \n",
      "                    data \n",
      "\u001b[36msync_data_from_s3  \u001b[m Download Data from S3 \n",
      "\u001b[36msync_data_to_s3    \u001b[m Upload Data to S3 \n",
      "\u001b[36mtest               \u001b[m Run all Unit Tests \n",
      "\u001b[36mtest_environment   \u001b[m Test python environment is set-up correctly \n",
      "\u001b[36mtrain              \u001b[m train / fit / build models \n",
      "\u001b[36mtransform_data     \u001b[m Apply Transformations to produce fully processed Datsets \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd .. && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: The Format of a Makefile\n",
    "\n",
    "```\n",
    "## Comment to appear in the auto-generated documentation\n",
    "thing_to_build: space separated list of dependencies\n",
    "\tcommand_to_run            # there is a tab before this command.\n",
    "\tanother_command_to_run    # every line gets run in a *new shell*\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Makefile.test\n"
     ]
    }
   ],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "data: raw\n",
    "\t@echo \"Build Datasets\"\n",
    "train_test_split:\n",
    "\t@echo \"do train/test split\"\n",
    "train: data transform_data train_test_split\n",
    "\t@echo \"Train Models\"\n",
    "transform_data:\n",
    "\t@echo \"do a data transformation\"\n",
    "raw:\n",
    "\t@echo \"Fetch raw data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see: ```*** missing separator.  Stop.```, it's because you have used spaces instead of **tabs** before your commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch raw data\n",
      "Build Datasets\n",
      "do a data transformation\n",
      "do train/test split\n",
      "Train Models\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "make -f Makefile.test train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Makefile.test\n"
     ]
    }
   ],
   "source": [
    "%%file Makefile.test\n",
    "\n",
    "cycle: cycle_b\n",
    "\t@echo \"in a Makefile\"\n",
    "cycle_b: cycle_c\n",
    "\t@echo \"have a cycle\"\n",
    "cycle_c: cycle\n",
    "\t@echo \"You can't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't\n",
      "have a cycle\n",
      "in a Makefile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "make: Circular cycle_c <- cycle dependency dropped.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "make -f Makefile.test cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Makefile like this is an easy way to set up a process flow expressed as a Directed Acyclic Graph (DAG).\n",
    "\n",
    "Note: We have only scratched the surface here. The are lots of interesting tricks you can do with make.\n",
    "* http://zmjones.com/make/\n",
    "* http://blog.byronjsmith.com/makefile-shortcuts.html\n",
    "* https://www.gnu.org/software/make/manual/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: Our Favourite Python Parts\n",
    "Why the `python>=3.6` requirement?\n",
    "* f-strings: Finally, long, readable strings in our code.\n",
    "* dictionaries: insertion order is preserved!\n",
    "\n",
    "Other great tools:\n",
    "* `pathlib`: Sane, multiplatorm path handling: https://realpython.com/python-pathlib/\n",
    "* `doctest`: Examples that always work: https://docs.python.org/3/library/doctest.html\n",
    "* `joblib`: Especially the persistence part: https://joblib.readthedocs.io/en/latest/persistence.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision Control and Git\n",
    "\n",
    "### ASIDE: Git vs Github\n",
    "Git is a tool, and by itself, only marginally useful. To use it effecively (especially within a team), you need a **process**. This is what GitHub, GitLab, BitBucket help you with.\n",
    "\n",
    "For a quick start, see out [Github Workflow Cheat Sheet](https://github.com/hackalog/bus_number/wiki/Github-Workflow-Cheat-Sheet)\n",
    "\n",
    "### ASIDE: Diffing Jupyter Notebooks\n",
    "\n",
    "Yes, you can `diff` your jupyter notebooks. The tool is called `nbdime`\n",
    "    \n",
    " https://nbdime.readthedocs.io/en/stable/index.html\n",
    "\n",
    "To enable it, \n",
    "* add `- nbdime` to the pip section of `environment.yml`\n",
    "* `make requirements`\n",
    "\n",
    "You will likely want to enable integrations with jupyter notebook and git:\n",
    "\n",
    "```\n",
    "nbdime extensions --enable   # Enable Jupyter Notebook extension\n",
    "nbdime config-git --enable   # Enable automatic nbdiff'ing in `git diff`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: The magic pip+conda glue:\n",
    "You might notice that most of our code is imported from a module called `src`. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import data_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic piece that makes this module work is in `enviroment.yml`, our conda environment specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: bus_number\r\n",
      "dependencies:\r\n",
      "  - pip\r\n",
      "  - pip:\r\n",
      "    - -e .\r\n",
      "    - python-dotenv>=0.5.1\r\n",
      "    - umap-learn\r\n",
      "  - setuptools\r\n",
      "  - wheel\r\n",
      "  - sphinx\r\n"
     ]
    }
   ],
   "source": [
    "!head ../environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `- -e .` line. This installs an editable version of the module described in `setup.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from setuptools import find_packages, setup\r\n",
      "\r\n",
      "setup(\r\n",
      "    name='src',\r\n",
      "    packages=find_packages(),\r\n",
      "    version='0.0.1',\r\n",
      "    description='Up Your Bus Number: A Primer for Reproducible Data Science',\r\n",
      "    author='Tutte Institute for Mathematics and Computing',\r\n",
      "    license='MIT',\r\n",
      ")\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bus_number]",
   "language": "python",
   "name": "conda-env-bus_number-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
