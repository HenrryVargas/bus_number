{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Dataset, available_datasets\n",
    "from src import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lvq-pak_test', 'lvq-pak_train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list = workflow.available_datasets()\n",
    "dataset_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall task: \n",
    "\n",
    "Train a supervised model on the lvq-pak. Try three different techniques, three times, and pick the one with the best accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = Dataset.load('lvq-pak_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.load('lvq-pak_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2943, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  9,  0, ...,  2,  6,  7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "*                                                                      *\n",
      "*                              LVQ_PAK                                 *\n",
      "*                                                                      *\n",
      "*                                The                                   *\n",
      "*                                                                      *\n",
      "*                   Learning  Vector  Quantization                     *\n",
      "*                                                                      *\n",
      "*                          Program  Package                            *\n",
      "*                                                                      *\n",
      "*                   Version 3.1 (April 7, 1995)                        *\n",
      "*                                                                      *\n",
      "*                          Prepared by the                             *\n",
      "*                    LVQ Programming Team of the                       *\n",
      "*                 Helsinki University of Technology                    *\n",
      "*           Laboratory of Computer and Information Science             *\n",
      "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\n",
      "*                              FINLAND                                 *\n",
      "*                                                                      *\n",
      "*                      Copyright (c) 1991-1995                         *\n",
      "*                                                                      *\n",
      "************************************************************************\n",
      "*                                                                      *\n",
      "*  NOTE: This program package is copyrighted in the sense that it      *\n",
      "*  may be used for scientific purposes. The package as a whole, or     *\n",
      "*  parts thereof, cannot be included or used in any commercial         *\n",
      "*  application without written permission granted by its producents.   *\n",
      "*  No programs contained in this package may be copied for commercial  *\n",
      "*  distribution.                                                       *\n",
      "*                                                                      *\n",
      "*  All comments concerning this program package may be sent to the     *\n",
      "*  e-mail address 'lvq@nucleus.hut.fi'.                                *\n",
      "*                                                                      *\n",
      "************************************************************************\n",
      "\n",
      "This package contains all the programs necessary for the correct\n",
      "application of certain LVQ (Learning Vector Quantization) algorithms\n",
      "in an arbitrary statistical classification or pattern recognition\n",
      "task.  To this package four options for the algorithms, the\n",
      "LVQ1, the LVQ2.1, the LVQ3 and the OLVQ1, have been selected.  \n",
      "\n",
      "In the implementation of the LVQ programs we have tried to use as\n",
      "simple a code as possible.  Therefore the programs are supposed to\n",
      "compile in various machines without any specific modifications made on\n",
      "the code.  All programs have been written in ANSI C.\n",
      "\n",
      "The lvq_pak program package includes the following files:\n",
      "  - Documentation:\n",
      "      README             this file\n",
      "      lvq_doc.ps         documentation in (c) PostScript format\n",
      "      lvq_doc.ps.Z       same as above but compressed\n",
      "      lvq_doc.txt        documentation in ASCII format\n",
      "  - Source file archives:\n",
      "      lvq_p3r1.exe       Self-extracting MS-DOS archive file\n",
      "      lvq_pak-3.1.tar    UNIX tape archive file\n",
      "      lvq_pak-3.1.tar.Z  same as above but compressed\n",
      "\n",
      "Installation in UNIX (in more detail, see lvq_doc.ps/txt):\n",
      "  - Uncompress lvq_pak-3.1.tar.Z\n",
      "  - Extract the files with \"tar xovf lvq_pak-3.1.tar\" which creates\n",
      "    the subdirectory lvq_pak-3.1\n",
      "  - Copy makefile.unix to the name makefile\n",
      "  - Revise switches in the makefile, if necessary\n",
      "  - Execute \"make\"\n",
      "\n",
      "Installation in MS-DOS (in more detail, see lvq_doc.ps/txt):\n",
      "  - By executing the command lvq_p3r1 the self-extracting archive\n",
      "    creates the directory lvq_pak.3r1 and extracts all the files in it\n",
      "  - You are supposed to use Borland C++ Version 3.1 and to have\n",
      "    all the necessary environment settings\n",
      "  - Copy the file makefile.dos to the name makefile\n",
      "  - Revise the compiler switches in the makefile, if necessary\n",
      "  - Execute \"make\"\n",
      "\n",
      "Revision history:\n",
      "  - Version 1.0 was released 19 December 1991.\n",
      "  - Version 1.1 containing only a minor bug fix in memory allocation\n",
      "    was released 31 December 1991.\n",
      "  - Version 2.0 containing major modifications in the algorithms was\n",
      "    released January 31, 1992.\n",
      "  - Version 2.1 containing some improvements in the speed of algorithms\n",
      "    and one new program was released October 9, 1992.\n",
      "  - Version 3.0 containing many advanced features conserning application\n",
      "    of the algorithms in large problems was released March 1, 1995; for\n",
      "    these changes see documentation.\n",
      "  - Version 3.1 containing only a bug fix in random ordering\n",
      "    was released 7 April 1995.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds_train.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an algorithm\n",
    "\n",
    "Let's start with one algorithm!\n",
    "\n",
    "`make train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/bus_number/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train.data, ds_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 s, sys: 182 ms, total: 33.2 s\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LinearSVC(random_state=42, max_iter=200000)\n",
    "model.fit(ds_train.data, ds_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it to predict\n",
    "`make predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 10, 14,  7,  1,  9,  4,  0,  0, 15, 18, 14, 11, 15,  2,  0,  9,\n",
       "        2, 15, 18, 14,  0,  2, 10,  0,  9,  0, 14,  2,  7,  0,  4, 15,  0,\n",
       "        2, 18,  8,  0,  0, 15,  7, 12,  2, 14,  4,  4,  0,  4,  0,  0, 11,\n",
       "        0, 18, 11,  0, 14,  2,  0,  7,  0, 14, 14,  9,  7,  2,  0, 18,  2,\n",
       "        0, 14,  0,  2,  2, 18, 18,  0,  2, 11, 18,  7,  2,  0, 12,  7, 19,\n",
       "        2, 16,  2,  2, 18,  9, 18, 15,  7,  0,  2,  7,  4, 14, 11, 10,  7,\n",
       "        2,  4,  0, 14,  4,  9,  0,  7,  5,  9,  7,  7, 19,  0,  0,  9,  0,\n",
       "       11,  0,  0, 18,  9, 11, 11,  2,  2,  0,  2, 11,  7, 12,  7, 19,  2,\n",
       "       18,  2,  0,  7, 11,  4,  0,  0,  7, 14,  0,  0,  2, 15, 15, 18,  4,\n",
       "       14,  0,  0,  0,  0,  0,  0,  7,  0,  0, 14, 14,  0,  2,  2,  7,  0,\n",
       "        2,  7,  2,  0,  0,  7,  2, 11, 14, 11,  2, 18, 11, 14, 11,  2,  2,\n",
       "       10,  0, 11,  0,  2, 10,  2,  0,  4, 15,  0, 15, 11, 18,  9,  4, 15,\n",
       "        3, 10, 11, 12, 13,  0,  0, 18, 12,  2,  7,  0, 12, 18,  0,  0, 18,\n",
       "        0,  7,  0,  0,  7,  4,  6,  0,  2,  7, 17,  0,  0,  2, 15, 15,  9,\n",
       "        0,  0,  4,  4, 14,  0, 14,  0, 12,  5,  0, 14, 10,  7, 11, 15,  4,\n",
       "       12, 11,  9,  6, 12,  2,  2,  2,  2,  4,  0,  2,  9,  2,  2, 12, 16,\n",
       "        2, 14,  9, 12,  9,  0,  7,  0, 14, 15, 10, 10,  2,  0, 17,  7,  2,\n",
       "        7,  0, 12,  0,  0, 11, 13,  2, 12,  0,  2,  7,  7,  9,  0,  7,  2,\n",
       "        2,  0,  4, 11,  0,  4,  0, 14, 15,  8,  0,  0,  7,  4,  4, 12, 15,\n",
       "       18,  2, 11, 13,  0,  0, 11, 16,  0, 12, 14,  2,  4,  4, 18, 10,  2,\n",
       "        0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0, 16,  4, 14,\n",
       "       12,  0, 14,  0,  0, 16,  2, 15, 18,  7, 12,  9, 14, 14, 14,  0, 14,\n",
       "       14,  0,  0,  2, 10, 12,  0,  7, 17, 14, 15, 14,  0,  2,  0, 10,  2,\n",
       "        0,  7,  7, 13, 11,  0, 12,  4,  7, 12, 14, 18,  0,  0,  2,  2,  2,\n",
       "        4, 12,  0, 14,  2,  0,  4,  0,  7, 14,  0, 18, 15,  4,  0, 15,  7,\n",
       "        2, 11,  7,  0, 18,  0,  0,  0,  2,  7,  0,  0, 12,  7, 11,  7, 15,\n",
       "        0, 14, 18,  7,  2, 14,  0, 10,  0,  0,  2, 14,  7,  0,  2,  6,  4,\n",
       "       11,  0, 13,  0,  0,  7,  0,  4,  2,  7,  0,  4,  0,  0,  0,  0,  0,\n",
       "        0, 14, 14,  7,  4,  6,  7,  0, 18,  0,  3, 15,  7, 11,  7,  0, 14,\n",
       "       11, 18,  7,  4,  2, 11, 11, 14,  2, 14,  0, 12,  2,  0,  2, 14,  0,\n",
       "       15,  4, 11, 11,  0, 11,  2, 14,  8,  0, 11, 11,  7,  4,  7,  0, 18,\n",
       "       18,  4, 12, 14, 14,  0, 18,  0,  0,  8, 14,  4,  7,  0,  0, 18, 15,\n",
       "        7,  7, 10,  7, 16,  4,  4, 14,  0,  4,  0,  0,  0,  4, 10, 11,  2,\n",
       "       12,  0, 11,  9,  7, 11,  0, 10,  0,  0,  7,  2,  0,  0,  0, 18, 14,\n",
       "        7, 18,  8, 10,  0,  0,  2,  7,  7,  2, 10,  7,  0, 11,  0, 12,  0,\n",
       "       12, 14, 14,  0, 16, 18,  4, 11,  2,  0,  0, 12,  9, 11,  0, 11,  9,\n",
       "       11,  9, 16,  0,  0, 10,  7,  4,  7, 14, 17,  7,  2,  2, 10,  2,  2,\n",
       "       11, 14,  9,  0,  2,  4, 14, 10, 11,  0,  4,  9, 16, 11,  0, 12, 14,\n",
       "        0, 11,  0,  9,  0,  0, 15,  0,  0, 10,  2, 15,  0, 12,  9,  0,  0,\n",
       "       10,  2,  0, 14, 11,  7,  4,  4,  0,  2,  9,  0, 14,  7,  0,  8, 18,\n",
       "        2, 15, 13,  4,  0,  7,  7,  2,  7,  0,  0,  2, 12,  2,  0, 18,  4,\n",
       "       14,  0, 10, 13,  2,  4, 12,  0,  2,  0, 18,  0, 12,  2,  2,  0,  4,\n",
       "        0, 18, 10,  4, 14,  2, 14,  2,  9,  7,  8,  0,  0, 11,  2, 15, 11,\n",
       "        4, 14,  9,  8, 11,  7, 14, 10,  0, 14,  0, 10,  2,  0, 12,  7, 12,\n",
       "        0,  0, 17,  2,  0,  2, 11,  0,  4,  7,  7, 18,  4, 18,  0, 18,  0,\n",
       "        7,  9, 12, 12, 11,  0, 18, 12, 14,  0,  7,  7,  0,  2, 13, 18,  0,\n",
       "        0,  0,  7,  0, 16, 14,  7,  4,  7, 18, 17,  7,  2,  4,  2,  0,  0,\n",
       "        0, 14, 12,  0,  0,  0,  7, 12,  0,  0, 10,  0,  0,  0,  0,  7, 18,\n",
       "        4, 18, 12,  0,  4, 12, 17,  7,  0, 16, 15,  4,  7,  0,  8,  0, 18,\n",
       "        0,  4,  9,  0,  7,  4, 10,  7, 18,  7, 15,  0, 16,  0,  2,  0,  0,\n",
       "       16,  0, 13, 14, 12, 12,  0,  9, 15, 14, 10,  0,  0,  2,  4,  4,  7,\n",
       "       11,  0,  2,  0,  0,  7,  2, 12,  0,  4, 10,  0,  0,  0,  2, 10,  0,\n",
       "        0, 11, 10,  0, 13,  7, 12,  2, 10,  0,  2,  2, 11,  7, 12,  0, 18,\n",
       "        0,  3,  4,  9, 12, 11, 10,  0, 15,  0,  0, 17, 11,  0, 11,  0, 16,\n",
       "        0,  0, 17,  0,  0,  0,  0, 15,  1,  9, 14, 14,  7, 13, 11, 18, 14,\n",
       "       11,  0,  2,  0,  4,  0, 10,  0,  7,  0,  2, 10,  4,  4,  4,  7,  7,\n",
       "        6, 15, 18,  4,  9, 12, 12, 11, 17,  2,  2,  0,  4,  2,  0, 12, 11,\n",
       "        7, 15,  8,  0,  0, 17,  0,  2,  0,  0,  0,  7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test = model.predict(ds_test.data);\n",
    "p_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the quality of the prediction\n",
    "`make analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8756371049949032"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(ds_test.data, ds_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8756371049949032"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ds_test.target, p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: \n",
    "* automate the basic workflow\n",
    "* compare 3 different algorithms run with 3 different random states for our Swedish Chef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: `make train`\n",
    "\n",
    "## Add our algorithm to available_algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently no available algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linearSVC',\n",
       " 'GradientBoostingClassifier',\n",
       " 'GridSearchCV',\n",
       " 'RandomForestClassifier']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an algorithm, add  a key:value pair to the dict `_ALGORITHMS` in `src/models/algorithms.py`.\n",
    "\n",
    "For example, add\n",
    "```\n",
    "'linearSVC': LinearSVC()\n",
    "```\n",
    "to the `_ALGORITHMS` dict, and add\n",
    "```\n",
    "from sklearn.svm import LinearSVC\n",
    "```\n",
    "to the top of the file.\n",
    "\n",
    "Also, add `linearSVC` to the docstring of `available_algorithms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linearSVC',\n",
       " 'GradientBoostingClassifier',\n",
       " 'GridSearchCV',\n",
       " 'RandomForestClassifier']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_algorithms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function available_algorithms in module src.models.algorithms:\n",
      "\n",
      "available_algorithms(keys_only=True)\n",
      "    Valid Algorithms for training or prediction\n",
      "    \n",
      "    This function simply returns a dict of known\n",
      "    algorithms strings and their corresponding estimator function.\n",
      "    \n",
      "    It exists to allow for a description of the mapping for\n",
      "    each of the valid strings as a docstring\n",
      "    \n",
      "    The valid algorithm names, and the function they map to, are:\n",
      "    \n",
      "    \n",
      "    ============                 ====================================\n",
      "    Algorithm                    Function\n",
      "    ============                 ====================================\n",
      "    LinearSVC                    sklearn.svm.LinearSVC\n",
      "    GradientBoostingClassifier   sklearn.ensemble.GradientBoostingClassifier\n",
      "    ============                 ====================================\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    keys_only: boolean\n",
      "        If True, return only keys. Otherwise, return a dictionary mapping keys to algorithms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(workflow.available_algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're in a position where the `make train` script can run using `linearSVC`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: *** No rule to make target `models/model_list.json', needed by `train'.  Stop.\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make -n train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that `make train` takes a `models/model_list.json` as input.\n",
    "```\n",
    "## train / fit / build models\n",
    "train: models/model_list.json\n",
    "\t$(PYTHON_INTERPRETER) -m src.models.train_model model_list.json\n",
    "```\n",
    "\n",
    "Under the hood, a `model_list.json` is a list of dicts, where each dict specifices a combination of:\n",
    "* `dataset_name`: A valid dataset name from `available_datasets`\n",
    "* `algorithm_name`: A valid dataset name from `available_algorithms`\n",
    "* `algorithm_params`: A dictionary of parameters to use when running the specified `algorithm`\n",
    "* `run_number`: (optional, default 1) A unique integer used to distinguish between different builds with otherwise identical parameters\n",
    "\n",
    "We don't need to know this, as we will use helper functions in `workflow` to build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_model(dataset_name='lvq-pak_train',\n",
    "                   algorithm_name=\"linearSVC\",\n",
    "                   algorithm_params={'random_state': 42, 'max_iter': 200000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'algorithm_name': 'linearSVC',\n",
       "  'algorithm_params': {'max_iter': 200000, 'random_state': 42},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_model_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running `make train` will train `LinearSVC` on `lvq-pak` with the specified parameters.\n",
    "\n",
    "Alternately, we can run `workflow.build_models()`.\n",
    "\n",
    "The output will be:\n",
    "* A trained model in `models/trained_models`\n",
    "* A json file `models/trained_models.json` that keeps track of the models that we've trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linearSVC_lvq-pak_train_1': {'algorithm_name': 'linearSVC',\n",
       "  'algorithm_params': {'C': 1.0,\n",
       "   'class_weight': None,\n",
       "   'dual': True,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_scaling': 1,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 200000,\n",
       "   'multi_class': 'ovr',\n",
       "   'penalty': 'l2',\n",
       "   'random_state': 42,\n",
       "   'tol': 0.0001,\n",
       "   'verbose': 0},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1,\n",
       "  'data_hash': 'ee5ba3c3b1cae9cac275d47832c404b688344dd1',\n",
       "  'target_hash': '2918cb40ea4eca1c1bd770a0d2fd179249407202',\n",
       "  'model_hash': 'b56909bb97424fd9ada4ad7c4306a95cece7b311'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m src.models.train_models model_list.json\n",
      "//anaconda/envs/bus_number/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2018-10-14 10:39:30,732 - train_models - INFO - Training complete! Access results via workflow.available_models\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Caching! Then, checking against existing files and metadata and looking for caching! (note: will need a force parameter eventually)\n",
    "\n",
    "## TODO: Don't overwrite the trained_models.json, append to it (as long as the files are still there) --- add call to available_models in build_models and give it a force option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at the output from `make train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import trained_model_path\n",
    "from src.utils import list_dir\n",
    "from src.utils import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoostingClassifier_lvq-pak_train_1',\n",
       " 'linearSVC_lvq-pak_train_1',\n",
       " 'GridSearchCV_lvq-pak_train_1']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the trained model\n",
    "from src.models.train import load_model\n",
    "\n",
    "tm, tm_metadata = load_model(model_name='linearSVC_lvq-pak_train_1', model_path=trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=200000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm_name': 'linearSVC',\n",
       " 'algorithm_params': {'C': 1.0,\n",
       "  'class_weight': None,\n",
       "  'dual': True,\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'loss': 'squared_hinge',\n",
       "  'max_iter': 200000,\n",
       "  'multi_class': 'ovr',\n",
       "  'penalty': 'l2',\n",
       "  'random_state': 42,\n",
       "  'tol': 0.0001,\n",
       "  'verbose': 0},\n",
       " 'data_hash': 'ee5ba3c3b1cae9cac275d47832c404b688344dd1',\n",
       " 'dataset_name': 'lvq-pak_train',\n",
       " 'model_hash': 'b56909bb97424fd9ada4ad7c4306a95cece7b311',\n",
       " 'run_number': 1,\n",
       " 'target_hash': '2918cb40ea4eca1c1bd770a0d2fd179249407202'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ee5ba3c3b1cae9cac275d47832c404b688344dd1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.load('lvq-pak_train')\n",
    "ds.DATA_HASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: explore the effects of caching once it's implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any algorithm will work that: \n",
    "* is a subclass of the sklearn `BaseEstimator` class (needed for setting and getting params)\n",
    "* has a `fit` method (needed for `make train`)\n",
    "* has either a `predict` method (supervised) or a `transform` method (unsupervised) (needed for `make predict`)\n",
    "\n",
    "We will see how things work in the unsupervised case in the next example. \n",
    "\n",
    "Note that an **algorithm** here can be a combination of \"algorithms\" as long as that combination is a `BaseEstimator` with the above methods. For example, you can use an sklearn pipeline, or an sklearn meta estimator like GridSearchCV as an algorithm. \n",
    "\n",
    "If your algorithm of choice is **not yet** a `BaseEstimator` with the appropriate API, it is fairly easy to wrap it to be used in this way. While we won't have time to cover an example of this during the in-person part of this tutorial, the EDA Text Embedding (advanced usage tutorial) has an example of how to do this with gensim's FastText model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: `make predict`\n",
    "\n",
    "```\n",
    "## predict / transform / run experiments\n",
    "predict: models/predict_list.json\n",
    "\t$(PYTHON_INTERPRETER) -m src.models.predict_model predict_list.json\n",
    "```\n",
    "\n",
    "Similar to `models_list.json` in `predict_list.json` we specify the dataset to operate on, and in this case, the `trained_model` to apply to the given dataset. Again, we do this using the `workflow` module.\n",
    "\n",
    "\n",
    "A `predict_list.json` is a list of dicts, where each dict specifices a combination of:\n",
    "* `dataset_name`: A valid dataset name from `available_datasets`\n",
    "* `dataset_params`: A dictionary of parameters that can be passed to `load_dataset()` with the specified `dataset`\n",
    "* `model_name`: A valid dataset name from `available_trained_models` (aka. a key name in `trained_models.json`\n",
    "* `is_supervised`: Whether to use the `predict` (supervised) or `transform` (unsupervised) method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the test set here to do the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_prediction(dataset_name='lvq-pak_test', model_name='linearSVC_lvq-pak_train_1', is_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_name': 'lvq-pak_test',\n",
       "  'is_supervised': True,\n",
       "  'model_name': 'linearSVC_lvq-pak_train_1'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_prediction_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-14 10:39:31,812 - predict - INFO - Experiment has already been run. Returning Cached Result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'linearSVC_lvq-pak_train_1_exp_lvq-pak_test_1': {'dataset_name': 'linearSVC_lvq-pak_train_1_exp_lvq-pak_test_1',\n",
       "  'hash_type': 'sha1',\n",
       "  'data_hash': '37b8e0111dc53ab39717d79fe0a67e13a9ebb265',\n",
       "  'target_hash': '5dab31bc1f020abc091c927aa9d420880171cb36',\n",
       "  'experiment': {'model_name': 'linearSVC_lvq-pak_train_1',\n",
       "   'dataset_name': 'lvq-pak_test',\n",
       "   'run_number': 1,\n",
       "   'hash_type': 'sha1',\n",
       "   'data_hash': '5561f5d951ec546bf9d221a2c7e60173c1f9beba',\n",
       "   'target_hash': '5dab31bc1f020abc091c927aa9d420880171cb36',\n",
       "   'model_hash': 'b56909bb97424fd9ada4ad7c4306a95cece7b311',\n",
       "   'start_time': 1539527535.5877252,\n",
       "   'duration': 0.00220489501953125}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.run_predictions(predict_file='predict_list.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m src.models.predict_model predict_list.json\n",
      "//anaconda/envs/bus_number/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2018-10-14 10:39:33,480 - predict - INFO - Experiment has already been run. Returning Cached Result\n",
      "2018-10-14 10:39:33,485 - predict_model - INFO - Predict complete! Results accessible via workflow.available_predictions\n"
     ]
    }
   ],
   "source": [
    "!cd .. && LOGLEVEL=INFO make predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GridSearchCV_lvq-pak_train_1_exp_lvq-pak_test_1',\n",
       " 'GradientBoostingClassifier_lvq-pak_train_1_exp_lvq-pak_test_1',\n",
       " 'linearSVC_lvq-pak_train_1_exp_lvq-pak_test_1']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import model_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Predictions are just Datasets tagged with experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ds = Dataset.load('linearSVC_lvq-pak_train_1_exp_lvq-pak_test_1', data_path=model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ds.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'linearSVC_lvq-pak_train_1',\n",
       " 'dataset_name': 'lvq-pak_test',\n",
       " 'run_number': 1,\n",
       " 'hash_type': 'sha1',\n",
       " 'data_hash': '5561f5d951ec546bf9d221a2c7e60173c1f9beba',\n",
       " 'target_hash': '5dab31bc1f020abc091c927aa9d420880171cb36',\n",
       " 'model_hash': 'b56909bb97424fd9ada4ad7c4306a95cece7b311',\n",
       " 'start_time': 1539527535.5877252,\n",
       " 'duration': 0.00220489501953125}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ds.metadata['experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check that our prediction matches\n",
    "all(predict_ds.data == p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Move this function to a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Dataset\n",
    "from src.paths import model_path, model_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_scorers():\n",
    "    _SCORERS = {\n",
    "        'accuracy_score': accuracy_score\n",
    "    }\n",
    "    return _SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_score_df(predict_json='predictions.json', predict_json_path=None,\n",
    "                        score_list=['accuracy_score']):\n",
    "    if predict_json_path is None:\n",
    "        predict_json_path = model_path\n",
    "    else:\n",
    "        predict_json_path = pathlib.Path(predict_json_path)\n",
    "    predictions = load_json(predict_json_path / predict_json)\n",
    "    score_df = pd.DataFrame(columns=['score_name', 'algorithm_name', 'dataset_name',\n",
    "                                     'model_name', 'run_number'])\n",
    "    for current_scorer_name in score_list:\n",
    "        current_scorer = available_scorers()[current_scorer_name]\n",
    "\n",
    "        score_dict = {}\n",
    "        score_dict['score_name'] = current_scorer_name\n",
    "        for key in predictions.keys():\n",
    "            prediction = predictions[key]\n",
    "            exp = prediction['experiment']\n",
    "            pred_ds = Dataset.load(prediction['dataset_name'], data_path=model_output_path)\n",
    "\n",
    "            ds_name = exp['dataset_name']\n",
    "            ds = Dataset.load(ds_name)\n",
    "            score_dict['dataset_name'] = ds_name\n",
    "\n",
    "            score_dict['score'] = current_scorer(ds.target, pred_ds.data)\n",
    "\n",
    "            model_metadata = load_model(model_name=exp['model_name'], metadata_only=True)\n",
    "            score_dict['algorithm_name'] = model_metadata['algorithm_name']\n",
    "            score_dict['model_name'] = exp['model_name']\n",
    "            score_dict['run_number'] = exp['run_number']\n",
    "            new_score_df = pd.DataFrame(score_dict, index=[0])\n",
    "            score_df = score_df.append(new_score_df, sort=True)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>run_number</th>\n",
       "      <th>score</th>\n",
       "      <th>score_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linearSVC</td>\n",
       "      <td>lvq-pak_test</td>\n",
       "      <td>linearSVC_lvq-pak_train_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875637</td>\n",
       "      <td>accuracy_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  algorithm_name  dataset_name                 model_name run_number  \\\n",
       "0      linearSVC  lvq-pak_test  linearSVC_lvq-pak_train_1          1   \n",
       "\n",
       "      score      score_name  \n",
       "0  0.875637  accuracy_score  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_score_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Add caching of the summary dfs to know if you're about to overwrite one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Add other algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Add GradientBoostingClassifier and some other sklearn Classifier of your choice\n",
    "\n",
    "### Advanced Exercise: Use GridSearchCV applied to your classifier of choice as the 3rd alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_model(\n",
    "    dataset_name = 'lvq-pak_train',\n",
    "    algorithm_name = 'GradientBoostingClassifier',\n",
    "    algorithm_params = {'random_state': 42}    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add your choice of classifier here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'algorithm_name': 'linearSVC',\n",
       "  'algorithm_params': {'max_iter': 200000, 'random_state': 42},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1},\n",
       " {'algorithm_name': 'GradientBoostingClassifier',\n",
       "  'algorithm_params': {'random_state': 42},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Take a look to see what's there\n",
    "workflow.get_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advanced example...see if you can make it work with this as well.\n",
    "\n",
    "workflow.add_model(\n",
    "    dataset_name = 'lvq-pak_train',\n",
    "    algorithm_name = 'GridSearchCV',\n",
    "    algorithm_params = {'alg_name': 'RandomForestClassifier',\n",
    "                             'alg_params': {'n_estimators': 200},\n",
    "                             'gridsearch_params':{'max_features':['sqrt', 'log2', 10],\n",
    "                                                   'max_depth':[5, 7, 9],\n",
    "                                                   'random_state':[42, 62345, 3457],\n",
    "                                                   },\n",
    "                             'params': {'cv': 3}\n",
    "                       }  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'algorithm_name': 'linearSVC',\n",
       "  'algorithm_params': {'max_iter': 200000, 'random_state': 42},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1},\n",
       " {'algorithm_name': 'GradientBoostingClassifier',\n",
       "  'algorithm_params': {'random_state': 42},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1},\n",
       " {'algorithm_name': 'GridSearchCV',\n",
       "  'algorithm_params': {'alg_name': 'RandomForestClassifier',\n",
       "   'alg_params': {'n_estimators': 200},\n",
       "   'gridsearch_params': {'max_depth': [5, 7, 9],\n",
       "    'max_features': ['sqrt', 'log2', 10],\n",
       "    'random_state': [42, 62345, 3457]},\n",
       "   'params': {'cv': 3}},\n",
       "  'dataset_name': 'lvq-pak_train',\n",
       "  'run_number': 1}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linearSVC': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=200000,\n",
       "      multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "      verbose=0),\n",
       " 'GradientBoostingClassifier': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               n_iter_no_change=None, presort='auto', random_state=None,\n",
       "               subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "               verbose=0, warm_start=False),\n",
       " 'GridSearchCV': ComboGridSearchCV(alg_name=None, alg_params=None, gridsearch_params=None,\n",
       "          params=None),\n",
       " 'RandomForestClassifier': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_algorithms(keys_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m src.models.train_models model_list.json\n",
      "//anaconda/envs/bus_number/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "//anaconda/envs/bus_number/lib/python3.6/site-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "2018-10-14 10:43:27,803 - train_models - INFO - Training complete! Access results via workflow.available_models\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoostingClassifier_lvq-pak_train_1',\n",
       " 'linearSVC_lvq-pak_train_1',\n",
       " 'GridSearchCV_lvq-pak_train_1']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_prediction_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up predictions using all of the available models\n",
    "for tm in workflow.available_models():\n",
    "    workflow.add_prediction(\n",
    "        dataset_name = 'lvq-pak_test',\n",
    "        model_name = tm,\n",
    "        is_supervised = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset_name': 'lvq-pak_test',\n",
       "  'force': False,\n",
       "  'is_supervised': True,\n",
       "  'model_name': 'GradientBoostingClassifier_lvq-pak_train_1'},\n",
       " {'dataset_name': 'lvq-pak_test',\n",
       "  'force': False,\n",
       "  'is_supervised': True,\n",
       "  'model_name': 'linearSVC_lvq-pak_train_1'},\n",
       " {'dataset_name': 'lvq-pak_test',\n",
       "  'force': False,\n",
       "  'is_supervised': True,\n",
       "  'model_name': 'GridSearchCV_lvq-pak_train_1'}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_prediction_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m src.models.predict_model predict_list.json\n",
      "//anaconda/envs/bus_number/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2018-10-14 11:04:28,179 - predict_model - DEBUG - Executing models from predict_list.json\n",
      "2018-10-14 11:04:30,886 - predict - DEBUG - Predict: Applying GradientBoostingClassifier_lvq-pak_train_1 on lvq-pak_test\n",
      "2018-10-14 11:04:30,887 - predict - INFO - Experiment has already been run. Returning Cached Result\n",
      "2018-10-14 11:04:31,029 - predict - DEBUG - Predict: Applying linearSVC_lvq-pak_train_1 on lvq-pak_test\n",
      "2018-10-14 11:04:31,030 - predict - INFO - Experiment has already been run. Returning Cached Result\n",
      "2018-10-14 11:04:31,516 - predict - DEBUG - Predict: Applying GridSearchCV_lvq-pak_train_1 on lvq-pak_test\n",
      "2018-10-14 11:04:31,517 - predict - INFO - Experiment has already been run. Returning Cached Result\n",
      "2018-10-14 11:04:31,521 - predict_model - INFO - Predict complete! Results accessible via workflow.available_predictions\n"
     ]
    }
   ],
   "source": [
    "!cd .. && LOGLEVEL=DEBUG make predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GridSearchCV_lvq-pak_train_1_exp_lvq-pak_test_1',\n",
       " 'GradientBoostingClassifier_lvq-pak_train_1_exp_lvq-pak_test_1',\n",
       " 'linearSVC_lvq-pak_train_1_exp_lvq-pak_test_1']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>run_number</th>\n",
       "      <th>score</th>\n",
       "      <th>score_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>lvq-pak_test</td>\n",
       "      <td>GradientBoostingClassifier_lvq-pak_train_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879715</td>\n",
       "      <td>accuracy_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV</td>\n",
       "      <td>lvq-pak_test</td>\n",
       "      <td>GridSearchCV_lvq-pak_train_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>accuracy_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linearSVC</td>\n",
       "      <td>lvq-pak_test</td>\n",
       "      <td>linearSVC_lvq-pak_train_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875637</td>\n",
       "      <td>accuracy_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               algorithm_name  dataset_name  \\\n",
       "0  GradientBoostingClassifier  lvq-pak_test   \n",
       "0                GridSearchCV  lvq-pak_test   \n",
       "0                   linearSVC  lvq-pak_test   \n",
       "\n",
       "                                   model_name run_number     score  \\\n",
       "0  GradientBoostingClassifier_lvq-pak_train_1          1  0.879715   \n",
       "0                GridSearchCV_lvq-pak_train_1          1  0.888889   \n",
       "0                   linearSVC_lvq-pak_train_1          1  0.875637   \n",
       "\n",
       "       score_name  \n",
       "0  accuracy_score  \n",
       "0  accuracy_score  \n",
       "0  accuracy_score  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = supervised_score_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Figure out where and how to include a \"lesson\" on random_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bus_number]",
   "language": "python",
   "name": "conda-env-bus_number-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
