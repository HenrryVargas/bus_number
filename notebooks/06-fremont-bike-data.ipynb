{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import RawDataset, Dataset\n",
    "from src.utils import list_dir, head_file, load_json, save_json\n",
    "from src import workflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = RawDataset(\"fremont_bike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds.add_url(url=\"https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD\", file_name=\"fremont.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_txt = \"Public Domain\"\n",
    "\n",
    "readme_txt = \"\"\"\n",
    "Fremont Bridge Hourly Bicycle Counts by Month October 2012 to present\n",
    "\n",
    "The Dataset is provided by the Seattle Department of Transportation Open Data initiative and is available from:\n",
    "https://data.seattle.gov/Transportation/Fremont-Bridge-Hourly-Bicycle-Counts-by-Month-Octo/65db-xm6k\n",
    "\n",
    "Description\n",
    "-----------\n",
    "The Fremont Bridge Bicycle Counter records the number of bikes that cross the bridge using the \n",
    "pedestrian/bicycle pathways. Inductive loops on the east and west pathways count the passing of bicycles \n",
    "regardless of travel direction. The data consists of a date/time field: Date, east pathway count field: \n",
    "Fremont Bridge NB, and west pathway count field: Fremont Bridge SB. The count fields represent the \n",
    "total bicycles detected during the specified one hour period. Direction of travel is not specified, \n",
    "but in general most traffic in the Fremont Bridge NB field is travelling northbound and most traffic in\n",
    "the Fremont Bridge SB field is travelling southbound.\n",
    "\n",
    "Data Format\n",
    "-----------\n",
    "The Dataset consists of a csv file with three columns:\n",
    "  Date, Fremont Bridge East Sidewalk, Fremont Bridge West Sidewalk\n",
    "Data consist of counts (in each direction) grouped by hour.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds.add_metadata(contents=license_txt, kind='LICENSE')\n",
    "raw_ds.add_metadata(contents=readme_txt, kind='DESCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do we have?\n",
    "unpack_dir = raw_ds.unpack()\n",
    "print(unpack_dir)\n",
    "list_dir(unpack_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check of data format\n",
    "print(head_file(unpack_dir / 'fremont.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at jvdp's example code. It basicall:\n",
    "data = pd.read_csv(unpack_dir / 'fremont.csv', index_col='Date')\n",
    "\n",
    "try:\n",
    "    data.index = pd.to_datetime(data.index, format='%m/%d/%Y %I:%M:%S %p')\n",
    "except TypeError:\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "data.columns = ['West', 'East']\n",
    "data['Total'] = data['West'] + data['East']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index().values; data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%file -a ../src/data/localdata.py\n",
    "#__all__ += ['process_fremont_bike']\n",
    "def process_fremont_bike(dataset_name=\"fremont_bike\", metadata=None):\n",
    "    \"\"\"Process Seattle DoT's Fremont Bridge Hourly Bicycle Counts\n",
    "    Data is available as a CSV.\n",
    "    Parse into a pandas.Dataframe and add a total column\n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    data = pd.read_csv(interim_data_path / dataset_name / 'fremont.csv', index_col='Date')\n",
    "\n",
    "    try:\n",
    "        data.index = pd.to_datetime(data.index, format='%m/%d/%Y %I:%M:%S %p')\n",
    "    except TypeError:\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "    data.columns = ['West', 'East']\n",
    "    data['Total'] = data['West'] + data['East']\n",
    "\n",
    "    return {\n",
    "        \"dataset_name\":dataset_name,\n",
    "        \"metadata\": metadata,\n",
    "        \"data\":data,\n",
    "        \"target\":None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import process_fremont_bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds.load_function = process_fremont_bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw dataset\n",
    "from src.data import Dataset\n",
    "#add_raw_dataset(raw_ds)\n",
    "\n",
    "workflow.add_raw_dataset(raw_ds)\n",
    "workflow.available_raw_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.paths import src_module_dir\n",
    "#dataset_list_fq = src_module_dir / 'data' / 'datasets.json'\n",
    "#dataset_list = load_json(dataset_list_fq)\n",
    "\n",
    "# workflow.create_dataset(raw_dataset_name=raw_ds.name) \n",
    "workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_transformer_list()\n",
    "#dataset_list.append({\"output_dataset\":'fremont_bike', 'raw_dataset_name':'fremont_bike'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_transformer(from_raw='fremont_bike')\n",
    "workflow.get_transformer_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.del_transformer(-1)\n",
    "workflow.get_transformer_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "workflow.apply_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. &&  make transform_data # same thing, but from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'fremont_bike' in workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load('fremont_bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a transformer to pivot the data\n",
    "#ds.data.pivot_table()\n",
    "ds.data.index.time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_date_time(dset, suffix='dt'):\n",
    "    \"\"\"Transformer: Extract a datetime index into Date and Time columns\"\"\"\n",
    "    df = dset.data.copy()\n",
    "    df['Time']=df.index.time\n",
    "    df['Date']=df.index.date\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    new_ds = Dataset(dataset_name=f\"{dset.name}_{suffix}\", metadata=dset.metadata, data=df)\n",
    "    return new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = index_to_date_time(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A transformer takes a dataset and returns a dataset\n",
    "def pivot(dset, **pivot_opts):\n",
    "    \"\"\"Pivot data stored as a Pandas Dataframe\n",
    "    \n",
    "    pivot_opts:\n",
    "        keyword arguments passed to pandas.Dataframe.pivot_table\n",
    "    \"\"\"\n",
    "    pivoted = dset.data.pivot_table(i**pivot_opts)\n",
    "    ds_pivot = Dataset(name=f\"{dset.name}_pivoted\", metadata=dset.metadata, data=pivoted, target=None)\n",
    "    ds_pivot.metadata['pivot_opts'] = pivot_opts\n",
    "\n",
    "    return ds_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.data.plot(legend=False, alpha=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.transformers import available_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_transformers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import src_module_dir\n",
    "\n",
    "transform_pipeline = [\n",
    "    ('index_to_date_time',{}),\n",
    "    ('pivot', {'values':'Total', 'index':'Time', 'columns':'Date'})\n",
    "]\n",
    "\n",
    "workflow.add_transformer(from_raw=\"fremont_bike\", output_dataset=\"fremont_bike_pivot\", transformations=transform_pipeline)\n",
    "workflow.add_transformer(input_dataset=\"fremont_bike\", output_dataset=\"fremont_bike_pivot2\", transformations=transform_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_transformer_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.apply_transforms()\n",
    "#!cd .. && make process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'fremont_bike_pivot' in workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two different pipelines should give us the same dataset\n",
    "One came from the raw dataset. The other from the dataset that was generated from the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp = Dataset.load('fremont_bike_pivot')\n",
    "dsp.DATA_HASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp2 = Dataset.load('fremont_bike_pivot2')\n",
    "dsp2.DATA_HASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.data.plot(legend=False, alpha=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bus_number]",
   "language": "python",
   "name": "conda-env-bus_number-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
