{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0: Reproducible Data Sources\n",
    "\"In God we trust. All others must bring data.” – W. Edwards Deming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from src.logging import logger\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the `DataSource`\n",
    "The `DataSource` object handles downloading, unpacking, and processing raw data files, and serves as a container for some basic metadata about the raw data, including **documentation** and **license** information.\n",
    "\n",
    "Raw data files are downloaded to  `paths.raw_data_path`.\n",
    " Cache files and unpacked raw files are saved to `paths.interim_data_path`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: LVQ-Pak,  a Finnish phonetic dataset\n",
    "The Learning Vector Quantization (lvq-pak) project includes a simple Finnish phonetic dataset\n",
    "consisting 20-dimensional Mel Frequency Cepstrum Coefficients (MFCCs) labelled with target phoneme information. Our goal is to explore this dataset, process it into a useful form, and make it a part of a reproducible data science workflow. The project can be found at: http://www.cis.hut.fi/research/lvq_pak/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this example, we are going create a `DataSource` for the LVQ-Pak dataset. The process will consist of\n",
    "1. Downloading and unpacking the raw data files. \n",
    "2. Generating (and recording) hash values for these files.\n",
    "3. Adding LICENSE and DESCR (description) metadata to this DataSource\n",
    "4. Adding the complete `DataSource` to the Catalog \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Raw Data Source Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import DataSource\n",
    "from src.utils import list_dir\n",
    "from src import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source object\n",
    "datasource_name = 'lvq-pak'\n",
    "dsrc = DataSource(datasource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add URL(s) for raw data files\n",
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:19,812 - fetch - DEBUG - No file_name specified. Inferring lvq_pak-3.1.tar from URL\n",
      "2019-02-08 14:49:19,815 - fetch - DEBUG - lvq_pak-3.1.tar exists, but no hash to check. Setting to sha1:86024a871724e521341da0ffb783956e39aadb6e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the files\n",
    "logger.setLevel(logging.DEBUG)\n",
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, data files are downloaded to the `paths.raw_data_path` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 740\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:48 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:48 lvq_pak-3.1.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not specify a hash, or target filename, these are inferred from the downloaded file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove a file from the file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that if we add a url again, we end up with more of the same file in the file list\n",
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': None,\n",
       "  'name': None,\n",
       "  'file_name': None}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:20,084 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:49:20,085 - fetch - DEBUG - No file_name specified. Inferring lvq_pak-3.1.tar from URL\n",
      "2019-02-08 14:49:20,088 - fetch - DEBUG - lvq_pak-3.1.tar exists, but no hash to check. Setting to sha1:86024a871724e521341da0ffb783956e39aadb6e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch is smart enough to not redownload the same file in this case. Still, this is messy and cumbersome. We can remove entries by removing them from the `file_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       " 'hash_type': 'sha1',\n",
       " 'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       " 'name': None,\n",
       " 'file_name': 'lvq_pak-3.1.tar'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:20,167 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sometimes we make mistakes when entering information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\", name='cat', file_name='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': None,\n",
       "  'name': 'cat',\n",
       "  'file_name': 'dog'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:20,252 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:49:21,386 - fetch - DEBUG - Retrieved dog (hash sha1:86024a871724e521341da0ffb783956e39aadb6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1472\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:48 lvq_pak-3.1.tar\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now  have a copy of `lvq_pak-3.1.tar` called `dog`. Every time we fetch, we will fetch twice unless we get rid of the entry for `dog`.\n",
    "\n",
    "First, we will want to remove `dog` from our raw data.\n",
    "\n",
    "Let's take the \"Nuke it from orbit. It's the only way to be sure\" approach and clean our entire raw data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f data/raw/*\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make clean_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwx--- 2 ava00125 domain users 4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users 4096 Oct 12 15:45 ..\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option would have been to manually remove the `dog` file and then forced a refetch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Remove the entry for dog and refetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwx--- 2 ava00125 domain users 4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users 4096 Oct 12 15:45 ..\r\n"
     ]
    }
   ],
   "source": [
    "# You should now only see the lvq_pak-3.1.tar file\n",
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cached Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataSource object keeps track of whether the fetch has been performed successfully. Subsequent downloads will be skipped by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:22,016 - datasets - DEBUG - Data Source lvq-pak is already fetched. Skipping\n"
     ]
    }
   ],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can override this, which will check if the downloaded file exists, redownloading if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:23,130 - fetch - DEBUG - Retrieved lvq_pak-3.1.tar (hash sha1:86024a871724e521341da0ffb783956e39aadb6e)\n",
      "2019-02-08 14:49:23,154 - fetch - DEBUG - Retrieved dog (hash sha1:86024a871724e521341da0ffb783956e39aadb6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous case, the raw data file existed on the filesystem, and had the correct hash. If the local file has a checksum that doesn't match the saved hash, it will be re-downloaded automatically. Let's corrupt the file and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"XXX\" >> $paths.raw_data_path/lvq_pak-3.1.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:23,330 - fetch - WARNING - lvq_pak-3.1.tar exists but has bad hash f575a5f139eb0072b415ab930005fd333afd7d0e. Re-downloading\n",
      "2019-02-08 14:49:23,620 - fetch - DEBUG - Retrieved lvq_pak-3.1.tar (hash sha1:86024a871724e521341da0ffb783956e39aadb6e)\n",
      "2019-02-08 14:49:23,623 - fetch - DEBUG - dog already exists and hash is valid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Creating an F-MNIST `DataSource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this excercise, you are going build a `DataSource` out of the Fashion-MNIST dataset.\n",
    "\n",
    "[Fashion-MNIST][FMNIST] is available from GitHub. Looking at their [README], we see that the raw data is distributed as a set of 4 files with the following checksums:\n",
    "\n",
    "[FMNIST]: https://github.com/zalandoresearch/fashion-mnist\n",
    "[README]: https://github.com/zalandoresearch/fashion-mnist/blob/master/README.md\n",
    "\n",
    "| Name  | Content | Examples | Size | Link | MD5 Checksum|\n",
    "| --- | --- |--- | --- |--- |--- |\n",
    "| `train-images-idx3-ubyte.gz`  | training set images  | 60,000|26 MBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz)|`8d4fb7e6c68d591d4c3dfef9ec88bf0d`|\n",
    "| `train-labels-idx1-ubyte.gz`  | training set labels  |60,000|29 KBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz)|`25c81989df183df01b3e8a0aad5dffbe`|\n",
    "| `t10k-images-idx3-ubyte.gz`  | test set images  | 10,000|4.3 MBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz)|`bef4ecab320f06d8554ea6380940ec79`|\n",
    "| `t10k-labels-idx1-ubyte.gz`  | test set labels  | 10,000| 5.1 KBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz)|`bb300cfdad3c16e7a12a480ee83cd310`|\n",
    "\n",
    "By the end of this running example, you will build a `DataSource` that downloads these raw files and verifies that the hash values are as expected. You should make sure to include **Description** and **License** metadata in this `DataSource`. When you are finished, save the `DataSource` to the Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Download Raw Data Source Files for F-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an fmnist data source object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add URL(s) for raw data files\n",
    "# Note that you will be adding four files to the DataSource object\n",
    "# and that the hash values have already been provided above!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1472\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n"
     ]
    }
   ],
   "source": [
    "# Check for your new files\n",
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking Raw Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:23,925 - fetch - DEBUG - Extracting lvq_pak-3.1.tar\n",
      "2019-02-08 14:49:23,934 - fetch - DEBUG - Copying dog\n"
     ]
    }
   ],
   "source": [
    "unpack_dir = dsrc.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, files are decompressed/unpacked to the `paths.interim_data_path`/`datasource_name` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 102408\r\n",
      "drwxrwx--- 6 ava00125 domain users     4096 Feb  8 12:29 .\r\n",
      "drwxrwx--- 5 ava00125 domain users     4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 47102837 Oct 10 20:58 048a21f52d05f88e50d70c47740ae1cf057549d2.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2359 Oct 10 20:58 048a21f52d05f88e50d70c47740ae1cf057549d2.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   458449 Oct 11 11:21 0f0f977903be6bd247b34c1ee1c9f4ef25befe28.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:21 0f0f977903be6bd247b34c1ee1c9f4ef25befe28.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users  7852836 Oct 10 20:58 1bdd754d481a6fe186e958508000a620555c61b7.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2358 Oct 10 20:58 1bdd754d481a6fe186e958508000a620555c61b7.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   905362 Oct 12 15:45 2c0bb10a816a7d45cce45984f1d5f9007c0a1d16.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 12 15:45 2c0bb10a816a7d45cce45984f1d5f9007c0a1d16.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   453724 Oct 11 11:21 5e81207b4e71774f57af2fbc958d2671900b68af.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:21 5e81207b4e71774f57af2fbc958d2671900b68af.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   905358 Oct 11 11:19 88e0484d8ef4aebcb1e3d49d8ede0eec5c5bdd57.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:19 88e0484d8ef4aebcb1e3d49d8ede0eec5c5bdd57.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users 47102837 Oct 10 20:58 d95a6db563698fce9ad2afc908c56a11c7693ade.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2359 Oct 10 20:58 d95a6db563698fce9ad2afc908c56a11c7693ade.metadata\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:05 fmnist\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Oct 10 17:05 f-mnist\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Oct 10 17:05 joblib\r\n",
      "drwxrwx--- 3 ava00125 domain users     4096 Feb  8 14:49 lvq-pak\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.interim_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We unpack everything into interim_data_path/datasource_name, which is returned by `unpack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 756\r\n",
      "drwxrwx--- 3 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 6 ava00125 domain users   4096 Feb  8 12:29 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "drwxr-xr-x 2 ava00125 domain users   4096 Apr  6  1995 lvq_pak-3.1\r\n",
      "-rw-rw---- 1 ava00125 domain users   2483 Oct 12 15:45 lvq-pak.license\r\n",
      "-rw-rw---- 1 ava00125 domain users   4958 Oct 12 15:45 lvq-pak.readme\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $unpack_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 780\r\n",
      "drwxr-xr-x 2 ava00125 domain users   4096 Apr  6  1995 .\r\n",
      "drwxrwx--- 3 ava00125 domain users   4096 Feb  8 14:49 ..\r\n",
      "-rw-r--r-- 1 ava00125 domain users   6358 Apr  6  1995 accuracy.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   7805 Apr  6  1995 balance.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   5577 Apr  6  1995 classify.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   7092 Apr  6  1995 cmatr.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3797 Apr  6  1995 config.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  28354 Apr  6  1995 datafile.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4294 Apr  6  1995 datafile.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users   5044 Apr  6  1995 elimin.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2626 Apr  6  1995 errors.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users   7122 Apr  6  1995 eveninit.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users 226894 Apr  6  1995 ex1.dat\r\n",
      "-rw-r--r-- 1 ava00125 domain users 225948 Apr  6  1995 ex2.dat\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4226 Apr  6  1995 extract.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users  10101 Apr  6  1995 fileio.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2896 Apr  6  1995 fileio.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users   6046 Apr  6  1995 knntest.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users  10459 Apr  6  1995 labels.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2665 Apr  6  1995 labels.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  15073 Apr  6  1995 lvq_pak.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   9279 Apr  6  1995 lvq_pak.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  25023 Apr  6  1995 lvq_rout.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   1402 Apr  6  1995 lvq_rout.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  34695 Apr  6  1995 lvq_run.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   8820 Apr  6  1995 lvqtrain.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3141 Apr  6  1995 makefile.dos\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3238 Apr  6  1995 makefile.unix\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4768 Apr  6  1995 mcnemar.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3957 Apr  6  1995 mindist.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2900 Apr  6  1995 pick.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4965 Apr  6  1995 README\r\n",
      "-rw-r--r-- 1 ava00125 domain users  13025 Apr  6  1995 sammon.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   5020 Apr  6  1995 setlabel.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3094 Apr  6  1995 showlabs.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3182 Apr  6  1995 stddev.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users     20 Apr  6  1995 VERSION\r\n",
      "-rw-r--r-- 1 ava00125 domain users    207 Apr  6  1995 version.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users     68 Apr  6  1995 version.h\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $unpack_dir/lvq_pak-3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Unpack raw data files for F-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for your files in the unpacked dirs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metadata to Raw Data\n",
    "Wait, what have we actually downloaded, and are we actually allowed to **use** this data? We keep track of two key pieces of metadata along with a raw dataset:\n",
    "* Description (`DESCR`) Text: Human-readable text describing the dataset, its source, and what it represents\n",
    "* License (`LICENSE`) Text: Terms of use for this dataset, often in the form of a license agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, a dataset comes complete with its own README and LICENSE files. If these are available via URL, we can add these like we add any other data file, tagging them as metadata using the `name` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/README\",\n",
    "               file_name='lvq-pak.readme', name='DESCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:24,493 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:49:24,496 - fetch - DEBUG - dog already exists and hash is valid\n",
      "2019-02-08 14:49:24,765 - fetch - DEBUG - Retrieved lvq-pak.readme (hash sha1:138b69cc0b4e02950cec5833752e50a54d36fd0f)\n",
      "2019-02-08 14:49:24,766 - datasets - DEBUG - Data Source lvq-pak is already unpacked. Skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/bus_number/data/interim/lvq-pak')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch()\n",
    "dsrc.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': 'cat',\n",
       "  'file_name': 'dog'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/README',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'lvq-pak.readme'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now fetch 2 files. Note the metadata has been tagged accordingly in the `name` field\n",
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to dig a little deeper to find the license. we find it at the beginning of the README file contained within that distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\r\n",
      "*                                                                      *\r\n",
      "*                              LVQ_PAK                                 *\r\n",
      "*                                                                      *\r\n",
      "*                                The                                   *\r\n",
      "*                                                                      *\r\n",
      "*                   Learning  Vector  Quantization                     *\r\n",
      "*                                                                      *\r\n",
      "*                          Program  Package                            *\r\n",
      "*                                                                      *\r\n",
      "*                   Version 3.1 (April 7, 1995)                        *\r\n",
      "*                                                                      *\r\n",
      "*                          Prepared by the                             *\r\n",
      "*                    LVQ Programming Team of the                       *\r\n",
      "*                 Helsinki University of Technology                    *\r\n",
      "*           Laboratory of Computer and Information Science             *\r\n",
      "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\r\n",
      "*                              FINLAND                                 *\r\n",
      "*                                                                      *\r\n",
      "*                      Copyright (c) 1991-1995                         *\r\n",
      "*                                                                      *\r\n",
      "************************************************************************\r\n",
      "*                                                                      *\r\n",
      "*  NOTE: This program package is copyrighted in the sense that it      *\r\n",
      "*  may be used for scientific purposes. The package as a whole, or     *\r\n",
      "*  parts thereof, cannot be included or used in any commercial         *\r\n",
      "*  application without written permission granted by its producents.   *\r\n",
      "*  No programs contained in this package may be copied for commercial  *\r\n",
      "*  distribution.                                                       *\r\n",
      "*                                                                      *\r\n",
      "*  All comments concerning this program package may be sent to the     *\r\n",
      "*  e-mail address 'lvq@cochlea.hut.fi'.                                *\r\n",
      "*                                                                      *\r\n",
      "************************************************************************\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -35 $paths.interim_data_path/lvq-pak/lvq_pak-3.1/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than trying to be clever, let's just add the license metadata from a python string that we cut and paste from the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_txt = '''\n",
    "************************************************************************\n",
    "*                                                                      *\n",
    "*                              LVQ_PAK                                 *\n",
    "*                                                                      *\n",
    "*                                The                                   *\n",
    "*                                                                      *\n",
    "*                   Learning  Vector  Quantization                     *\n",
    "*                                                                      *\n",
    "*                          Program  Package                            *\n",
    "*                                                                      *\n",
    "*                   Version 3.1 (April 7, 1995)                        *\n",
    "*                                                                      *\n",
    "*                          Prepared by the                             *\n",
    "*                    LVQ Programming Team of the                       *\n",
    "*                 Helsinki University of Technology                    *\n",
    "*           Laboratory of Computer and Information Science             *\n",
    "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\n",
    "*                              FINLAND                                 *\n",
    "*                                                                      *\n",
    "*                      Copyright (c) 1991-1995                         *\n",
    "*                                                                      *\n",
    "************************************************************************\n",
    "*                                                                      *\n",
    "*  NOTE: This program package is copyrighted in the sense that it      *\n",
    "*  may be used for scientific purposes. The package as a whole, or     *\n",
    "*  parts thereof, cannot be included or used in any commercial         *\n",
    "*  application without written permission granted by its producents.   *\n",
    "*  No programs contained in this package may be copied for commercial  *\n",
    "*  distribution.                                                       *\n",
    "*                                                                      *\n",
    "*  All comments concerning this program package may be sent to the     *\n",
    "*  e-mail address 'lvq@nucleus.hut.fi'.                                *\n",
    "*                                                                      *\n",
    "************************************************************************\n",
    "'''\n",
    "dsrc.add_metadata(contents=license_txt, kind='LICENSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, this will create a file, storing the creation instructions in the same `file_list` we use to store the URLs we wish to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': 'cat',\n",
       "  'file_name': 'dog'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/README',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'lvq-pak.readme'},\n",
       " {'contents': \"\\n************************************************************************\\n*                                                                      *\\n*                              LVQ_PAK                                 *\\n*                                                                      *\\n*                                The                                   *\\n*                                                                      *\\n*                   Learning  Vector  Quantization                     *\\n*                                                                      *\\n*                          Program  Package                            *\\n*                                                                      *\\n*                   Version 3.1 (April 7, 1995)                        *\\n*                                                                      *\\n*                          Prepared by the                             *\\n*                    LVQ Programming Team of the                       *\\n*                 Helsinki University of Technology                    *\\n*           Laboratory of Computer and Information Science             *\\n*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\\n*                              FINLAND                                 *\\n*                                                                      *\\n*                      Copyright (c) 1991-1995                         *\\n*                                                                      *\\n************************************************************************\\n*                                                                      *\\n*  NOTE: This program package is copyrighted in the sense that it      *\\n*  may be used for scientific purposes. The package as a whole, or     *\\n*  parts thereof, cannot be included or used in any commercial         *\\n*  application without written permission granted by its producents.   *\\n*  No programs contained in this package may be copied for commercial  *\\n*  distribution.                                                       *\\n*                                                                      *\\n*  All comments concerning this program package may be sent to the     *\\n*  e-mail address 'lvq@nucleus.hut.fi'.                                *\\n*                                                                      *\\n************************************************************************\\n\",\n",
       "  'file_name': 'lvq-pak.license',\n",
       "  'name': 'LICENSE'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we fetch, the license file is created from this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:25,027 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:49:25,030 - fetch - DEBUG - dog already exists and hash is valid\n",
      "2019-02-08 14:49:25,032 - fetch - DEBUG - lvq-pak.readme already exists and hash is valid\n",
      "2019-02-08 14:49:25,033 - fetch - DEBUG - Creating lvq-pak.license from `contents` string\n",
      "2019-02-08 14:49:25,045 - fetch - DEBUG - lvq-pak.license exists, but no hash to check. Setting to sha1:e5f53b172926d34cb6a49877be49ee08bc4d51c1\n",
      "2019-02-08 14:49:25,046 - datasets - DEBUG - Data Source lvq-pak is already unpacked. Skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/bus_number/data/interim/lvq-pak')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "dsrc.fetch(force=True)\n",
    "dsrc.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1484\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n",
      "-rw-rw---- 1 ava00125 domain users   2483 Feb  8 14:49 lvq-pak.license\r\n",
      "-rw-rw---- 1 ava00125 domain users   4958 Feb  8 14:49 lvq-pak.readme\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Add metadata to F-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Raw Data to the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmnist', 'lvq-pak']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_datasource(dsrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmnist', 'lvq-pak']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of this raw dataset catalog later in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Punchline, how to get at an existing DataSource from workflow and use it\n",
    "## Should be able to `make raw`...what happened to that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can blow away all the data that we've downloaded and set up so far, and recreate it from the workflow datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f data/raw/*\r\n",
      "rm -rf data/interim/*\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make clean_raw && make clean_interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwx--- 2 ava00125 domain users 4096 Feb  8 14:53 .\r\n",
      "drwxrwx--- 5 ava00125 domain users 4096 Oct 12 15:45 ..\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: *** No rule to make target `raw'.  Stop.\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. & make raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want the following line to give me back the available DataSource called `lvq-pak`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = workflow.DataSource(name='lvq-pak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data.datasets.DataSource at 0x7f180f766710>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Add F-MNIST to the Raw Dataset Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmnist', 'lvq-pak']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your fmnist dataset should now show up here:\n",
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
