{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0: Reproducible Data Sources\n",
    "\"In God we trust. All others must bring data.” – W. Edwards Deming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from src.logging import logger\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the `DataSource`\n",
    "The `DataSource` object handles downloading, unpacking, and processing raw data files, and serves as a container for some basic metadata about the raw data, including **documentation** and **license** information.\n",
    "\n",
    "Raw data files are downloaded to  `paths.raw_data_path`.\n",
    " Cache files and unpacked raw files are saved to `paths.interim_data_path`.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: LVQ-Pak,  a Finnish phonetic dataset\n",
    "The Learning Vector Quantization (lvq-pak) project includes a simple Finnish phonetic dataset\n",
    "consisting 20-dimensional Mel Frequency Cepstrum Coefficients (MFCCs) labelled with target phoneme information. Our goal is to explore this dataset, process it into a useful form, and make it a part of a reproducible data science workflow. The project can be found at: http://www.cis.hut.fi/research/lvq_pak/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For this example, we are going create a `DataSource` for the LVQ-Pak dataset. The process will consist of\n",
    "1. Downloading and unpacking the raw data files. \n",
    "2. Generating (and recording) hash values for these files.\n",
    "3. Adding LICENSE and DESCR (description) metadata to this DataSource\n",
    "4. Adding the complete `DataSource` to the Catalog \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Raw Data Source Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import DataSource\n",
    "from src.utils import list_dir\n",
    "from src import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source object\n",
    "datasource_name = 'lvq-pak'\n",
    "dsrc = DataSource(datasource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add URL(s) for raw data files\n",
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:53,214 - fetch - DEBUG - No file_name specified. Inferring lvq_pak-3.1.tar from URL\n",
      "2019-02-08 14:49:53,218 - fetch - DEBUG - lvq_pak-3.1.tar exists, but no hash to check. Setting to sha1:86024a871724e521341da0ffb783956e39aadb6e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the files\n",
    "logger.setLevel(logging.DEBUG)\n",
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, data files are downloaded to the `paths.raw_data_path` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1484\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n",
      "-rw-rw---- 1 ava00125 domain users   2483 Feb  8 14:49 lvq-pak.license\r\n",
      "-rw-rw---- 1 ava00125 domain users   4958 Feb  8 14:49 lvq-pak.readme\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not specify a hash, or target filename, these are inferred from the downloaded file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove a file from the file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that if we add a url again, we end up with more of the same file in the file list\n",
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': None,\n",
       "  'name': None,\n",
       "  'file_name': None}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:53,480 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:49:53,481 - fetch - DEBUG - No file_name specified. Inferring lvq_pak-3.1.tar from URL\n",
      "2019-02-08 14:49:53,486 - fetch - DEBUG - lvq_pak-3.1.tar exists, but no hash to check. Setting to sha1:86024a871724e521341da0ffb783956e39aadb6e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch is smart enough to not redownload the same file in this case. Still, this is messy and cumbersome. We can remove entries by removing them from the `file_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       " 'hash_type': 'sha1',\n",
       " 'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       " 'name': None,\n",
       " 'file_name': 'lvq_pak-3.1.tar'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:53,589 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sometimes we make mistakes when entering information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar\", name='cat', file_name='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': None,\n",
       "  'name': 'cat',\n",
       "  'file_name': 'dog'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:53,672 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:49:53,676 - fetch - DEBUG - dog exists, but no hash to check. Setting to sha1:86024a871724e521341da0ffb783956e39aadb6e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1484\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n",
      "-rw-rw---- 1 ava00125 domain users   2483 Feb  8 14:49 lvq-pak.license\r\n",
      "-rw-rw---- 1 ava00125 domain users   4958 Feb  8 14:49 lvq-pak.readme\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now  have a copy of `lvq_pak-3.1.tar` called `dog`. Every time we fetch, we will fetch twice unless we get rid of the entry for `dog`.\n",
    "\n",
    "First, we will want to remove `dog` from our raw data.\n",
    "\n",
    "Let's take the \"Nuke it from orbit. It's the only way to be sure\" approach and clean our entire raw data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f data/raw/*\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make clean_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwx--- 2 ava00125 domain users 4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users 4096 Oct 12 15:45 ..\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option would have been to manually remove the `dog` file and then forced a refetch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Remove the entry for dog and refetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': 'cat',\n",
       "  'file_name': 'dog'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       " 'hash_type': 'sha1',\n",
       " 'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       " 'name': 'cat',\n",
       " 'file_name': 'dog'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:55,269 - fetch - DEBUG - Retrieved lvq_pak-3.1.tar (hash sha1:86024a871724e521341da0ffb783956e39aadb6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fetch here will need to be forced\n",
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 740\r\n",
      "drwxrwx--- 2 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users   4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n"
     ]
    }
   ],
   "source": [
    "# You should now only see the lvq_pak-3.1.tar file\n",
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cached Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataSource object keeps track of whether the fetch has been performed successfully. Subsequent downloads will be skipped by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:55,445 - datasets - DEBUG - Data Source lvq-pak is already fetched. Skipping\n"
     ]
    }
   ],
   "source": [
    "dsrc.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can override this, which will check if the downloaded file exists, redownloading if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:55,468 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous case, the raw data file existed on the filesystem, and had the correct hash. If the local file has a checksum that doesn't match the saved hash, it will be re-downloaded automatically. Let's corrupt the file and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"XXX\" >> $paths.raw_data_path/lvq_pak-3.1.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:55,634 - fetch - WARNING - lvq_pak-3.1.tar exists but has bad hash f575a5f139eb0072b415ab930005fd333afd7d0e. Re-downloading\n",
      "2019-02-08 14:49:55,652 - fetch - DEBUG - Retrieved lvq_pak-3.1.tar (hash sha1:86024a871724e521341da0ffb783956e39aadb6e)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Creating an F-MNIST `DataSource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this excercise, you are going build a `DataSource` out of the Fashion-MNIST dataset.\n",
    "\n",
    "[Fashion-MNIST][FMNIST] is available from GitHub. Looking at their [README], we see that the raw data is distributed as a set of 4 files with the following checksums:\n",
    "\n",
    "[FMNIST]: https://github.com/zalandoresearch/fashion-mnist\n",
    "[README]: https://github.com/zalandoresearch/fashion-mnist/blob/master/README.md\n",
    "\n",
    "| Name  | Content | Examples | Size | Link | MD5 Checksum|\n",
    "| --- | --- |--- | --- |--- |--- |\n",
    "| `train-images-idx3-ubyte.gz`  | training set images  | 60,000|26 MBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz)|`8d4fb7e6c68d591d4c3dfef9ec88bf0d`|\n",
    "| `train-labels-idx1-ubyte.gz`  | training set labels  |60,000|29 KBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz)|`25c81989df183df01b3e8a0aad5dffbe`|\n",
    "| `t10k-images-idx3-ubyte.gz`  | test set images  | 10,000|4.3 MBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz)|`bef4ecab320f06d8554ea6380940ec79`|\n",
    "| `t10k-labels-idx1-ubyte.gz`  | test set labels  | 10,000| 5.1 KBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz)|`bb300cfdad3c16e7a12a480ee83cd310`|\n",
    "\n",
    "By the end of this running example, you will build a `DataSource` that downloads these raw files and verifies that the hash values are as expected. You should make sure to include **Description** and **License** metadata in this `DataSource`. When you are finished, save the `DataSource` to the Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Download Raw Data Source Files for F-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an fmnist data source object\n",
    "fmnist_dsname = 'fmnist'\n",
    "fmnist = DataSource(fmnist_dsname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add URL(s) for raw data files\n",
    "# Note that you will be adding four files to the DataSource object\n",
    "# and that the hash values have already been provided above!\n",
    "fmnist.add_url(url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "               hash_type='md5',\n",
    "               hash_value='8d4fb7e6c68d591d4c3dfef9ec88bf0d',\n",
    "               name='train-images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now all the rest at once\n",
    "url_base = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com'\n",
    "file_list = [\n",
    "    ('train-labels-idx1-ubyte.gz','25c81989df183df01b3e8a0aad5dffbe', 'train-labels'),\n",
    "    ('t10k-images-idx3-ubyte.gz', 'bef4ecab320f06d8554ea6380940ec79', 'test-images'),\n",
    "    ('t10k-labels-idx1-ubyte.gz', 'bb300cfdad3c16e7a12a480ee83cd310', 'test-labels'),\n",
    "]\n",
    "for file, hashval, name in file_list:\n",
    "    url = f\"{url_base}/{file}\"\n",
    "    fmnist.add_url(url=url, hash_type='md5', hash_value=hashval, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '8d4fb7e6c68d591d4c3dfef9ec88bf0d',\n",
       "  'name': 'train-images',\n",
       "  'file_name': None},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '25c81989df183df01b3e8a0aad5dffbe',\n",
       "  'name': 'train-labels',\n",
       "  'file_name': None},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bef4ecab320f06d8554ea6380940ec79',\n",
       "  'name': 'test-images',\n",
       "  'file_name': None},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bb300cfdad3c16e7a12a480ee83cd310',\n",
       "  'name': 'test-labels',\n",
       "  'file_name': None}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:55,765 - fetch - DEBUG - No file_name specified. Inferring train-images-idx3-ubyte.gz from URL\n",
      "2019-02-08 14:49:58,714 - fetch - DEBUG - Retrieved train-images-idx3-ubyte.gz (hash md5:8d4fb7e6c68d591d4c3dfef9ec88bf0d)\n",
      "2019-02-08 14:49:58,717 - fetch - DEBUG - No file_name specified. Inferring train-labels-idx1-ubyte.gz from URL\n",
      "2019-02-08 14:49:58,844 - fetch - DEBUG - Retrieved train-labels-idx1-ubyte.gz (hash md5:25c81989df183df01b3e8a0aad5dffbe)\n",
      "2019-02-08 14:49:58,845 - fetch - DEBUG - No file_name specified. Inferring t10k-images-idx3-ubyte.gz from URL\n",
      "2019-02-08 14:49:59,457 - fetch - DEBUG - Retrieved t10k-images-idx3-ubyte.gz (hash md5:bef4ecab320f06d8554ea6380940ec79)\n",
      "2019-02-08 14:49:59,458 - fetch - DEBUG - No file_name specified. Inferring t10k-labels-idx1-ubyte.gz from URL\n",
      "2019-02-08 14:49:59,469 - fetch - DEBUG - Retrieved t10k-labels-idx1-ubyte.gz (hash md5:bb300cfdad3c16e7a12a480ee83cd310)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the files\n",
    "fmnist.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 30904\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 5 ava00125 domain users     4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users   747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n",
      "-rw-rw---- 1 ava00125 domain users  4422102 Feb  8 14:49 t10k-images-idx3-ubyte.gz\r\n",
      "-rw-rw---- 1 ava00125 domain users     5148 Feb  8 14:49 t10k-labels-idx1-ubyte.gz\r\n",
      "-rw-rw---- 1 ava00125 domain users 26421880 Feb  8 14:49 train-images-idx3-ubyte.gz\r\n",
      "-rw-rw---- 1 ava00125 domain users    29515 Feb  8 14:49 train-labels-idx1-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "# Check for your new files\n",
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking Raw Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:49:59,664 - fetch - DEBUG - Extracting lvq_pak-3.1.tar\n"
     ]
    }
   ],
   "source": [
    "unpack_dir = dsrc.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, files are decompressed/unpacked to the `paths.interim_data_path`/`datasource_name` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 102408\r\n",
      "drwxrwx--- 6 ava00125 domain users     4096 Feb  8 12:29 .\r\n",
      "drwxrwx--- 5 ava00125 domain users     4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 47102837 Oct 10 20:58 048a21f52d05f88e50d70c47740ae1cf057549d2.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2359 Oct 10 20:58 048a21f52d05f88e50d70c47740ae1cf057549d2.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   458449 Oct 11 11:21 0f0f977903be6bd247b34c1ee1c9f4ef25befe28.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:21 0f0f977903be6bd247b34c1ee1c9f4ef25befe28.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users  7852836 Oct 10 20:58 1bdd754d481a6fe186e958508000a620555c61b7.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2358 Oct 10 20:58 1bdd754d481a6fe186e958508000a620555c61b7.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   905362 Oct 12 15:45 2c0bb10a816a7d45cce45984f1d5f9007c0a1d16.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 12 15:45 2c0bb10a816a7d45cce45984f1d5f9007c0a1d16.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   453724 Oct 11 11:21 5e81207b4e71774f57af2fbc958d2671900b68af.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:21 5e81207b4e71774f57af2fbc958d2671900b68af.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   905358 Oct 11 11:19 88e0484d8ef4aebcb1e3d49d8ede0eec5c5bdd57.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:19 88e0484d8ef4aebcb1e3d49d8ede0eec5c5bdd57.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users 47102837 Oct 10 20:58 d95a6db563698fce9ad2afc908c56a11c7693ade.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2359 Oct 10 20:58 d95a6db563698fce9ad2afc908c56a11c7693ade.metadata\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:05 fmnist\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Oct 10 17:05 f-mnist\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Oct 10 17:05 joblib\r\n",
      "drwxrwx--- 3 ava00125 domain users     4096 Feb  8 14:49 lvq-pak\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.interim_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We unpack everything into interim_data_path/datasource_name, which is returned by `unpack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 756\r\n",
      "drwxrwx--- 3 ava00125 domain users   4096 Feb  8 14:49 .\r\n",
      "drwxrwx--- 6 ava00125 domain users   4096 Feb  8 12:29 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 747520 Feb  8 14:49 dog\r\n",
      "drwxr-xr-x 2 ava00125 domain users   4096 Apr  6  1995 lvq_pak-3.1\r\n",
      "-rw-rw---- 1 ava00125 domain users   2483 Oct 12 15:45 lvq-pak.license\r\n",
      "-rw-rw---- 1 ava00125 domain users   4958 Oct 12 15:45 lvq-pak.readme\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $unpack_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 780\r\n",
      "drwxr-xr-x 2 ava00125 domain users   4096 Apr  6  1995 .\r\n",
      "drwxrwx--- 3 ava00125 domain users   4096 Feb  8 14:49 ..\r\n",
      "-rw-r--r-- 1 ava00125 domain users   6358 Apr  6  1995 accuracy.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   7805 Apr  6  1995 balance.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   5577 Apr  6  1995 classify.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   7092 Apr  6  1995 cmatr.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3797 Apr  6  1995 config.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  28354 Apr  6  1995 datafile.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4294 Apr  6  1995 datafile.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users   5044 Apr  6  1995 elimin.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2626 Apr  6  1995 errors.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users   7122 Apr  6  1995 eveninit.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users 226894 Apr  6  1995 ex1.dat\r\n",
      "-rw-r--r-- 1 ava00125 domain users 225948 Apr  6  1995 ex2.dat\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4226 Apr  6  1995 extract.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users  10101 Apr  6  1995 fileio.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2896 Apr  6  1995 fileio.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users   6046 Apr  6  1995 knntest.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users  10459 Apr  6  1995 labels.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2665 Apr  6  1995 labels.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  15073 Apr  6  1995 lvq_pak.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   9279 Apr  6  1995 lvq_pak.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  25023 Apr  6  1995 lvq_rout.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   1402 Apr  6  1995 lvq_rout.h\r\n",
      "-rw-r--r-- 1 ava00125 domain users  34695 Apr  6  1995 lvq_run.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   8820 Apr  6  1995 lvqtrain.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3141 Apr  6  1995 makefile.dos\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3238 Apr  6  1995 makefile.unix\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4768 Apr  6  1995 mcnemar.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3957 Apr  6  1995 mindist.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   2900 Apr  6  1995 pick.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   4965 Apr  6  1995 README\r\n",
      "-rw-r--r-- 1 ava00125 domain users  13025 Apr  6  1995 sammon.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   5020 Apr  6  1995 setlabel.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3094 Apr  6  1995 showlabs.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users   3182 Apr  6  1995 stddev.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users     20 Apr  6  1995 VERSION\r\n",
      "-rw-r--r-- 1 ava00125 domain users    207 Apr  6  1995 version.c\r\n",
      "-rw-r--r-- 1 ava00125 domain users     68 Apr  6  1995 version.h\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $unpack_dir/lvq_pak-3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Unpack raw data files for F-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:50:00,175 - fetch - DEBUG - Ungzipping train-images-idx3-ubyte\n",
      "2019-02-08 14:50:00,612 - fetch - DEBUG - Ungzipping train-labels-idx1-ubyte\n",
      "2019-02-08 14:50:00,616 - fetch - DEBUG - Ungzipping t10k-images-idx3-ubyte\n",
      "2019-02-08 14:50:00,694 - fetch - DEBUG - Ungzipping t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "fmnist_unpack = fmnist.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/bus_number/data/interim/fmnist')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist_unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 102408\r\n",
      "drwxrwx--- 6 ava00125 domain users     4096 Feb  8 12:29 .\r\n",
      "drwxrwx--- 5 ava00125 domain users     4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users 47102837 Oct 10 20:58 048a21f52d05f88e50d70c47740ae1cf057549d2.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2359 Oct 10 20:58 048a21f52d05f88e50d70c47740ae1cf057549d2.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   458449 Oct 11 11:21 0f0f977903be6bd247b34c1ee1c9f4ef25befe28.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:21 0f0f977903be6bd247b34c1ee1c9f4ef25befe28.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users  7852836 Oct 10 20:58 1bdd754d481a6fe186e958508000a620555c61b7.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2358 Oct 10 20:58 1bdd754d481a6fe186e958508000a620555c61b7.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   905362 Oct 12 15:45 2c0bb10a816a7d45cce45984f1d5f9007c0a1d16.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 12 15:45 2c0bb10a816a7d45cce45984f1d5f9007c0a1d16.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   453724 Oct 11 11:21 5e81207b4e71774f57af2fbc958d2671900b68af.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:21 5e81207b4e71774f57af2fbc958d2671900b68af.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users   905358 Oct 11 11:19 88e0484d8ef4aebcb1e3d49d8ede0eec5c5bdd57.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     7743 Oct 11 11:19 88e0484d8ef4aebcb1e3d49d8ede0eec5c5bdd57.metadata\r\n",
      "-rw-rw---- 1 ava00125 domain users 47102837 Oct 10 20:58 d95a6db563698fce9ad2afc908c56a11c7693ade.dataset\r\n",
      "-rw-rw---- 1 ava00125 domain users     2359 Oct 10 20:58 d95a6db563698fce9ad2afc908c56a11c7693ade.metadata\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:05 fmnist\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Oct 10 17:05 f-mnist\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Oct 10 17:05 joblib\r\n",
      "drwxrwx--- 3 ava00125 domain users     4096 Feb  8 14:49 lvq-pak\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.interim_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53812\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:05 .\r\n",
      "drwxrwx--- 6 ava00125 domain users     4096 Feb  8 12:29 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users    62432 Feb  8 14:11 fmnist.LICENSE\r\n",
      "-rw-rw---- 1 ava00125 domain users     1144 Feb  8 14:11 fmnist.readme\r\n",
      "-rw-rw---- 1 ava00125 domain users    62425 Feb  8 14:07 LICENSE\r\n",
      "-rw-rw---- 1 ava00125 domain users  7840016 Feb  8 14:50 t10k-images-idx3-ubyte\r\n",
      "-rw-rw---- 1 ava00125 domain users    10008 Feb  8 14:50 t10k-labels-idx1-ubyte\r\n",
      "-rw-rw---- 1 ava00125 domain users 47040016 Feb  8 14:50 train-images-idx3-ubyte\r\n",
      "-rw-rw---- 1 ava00125 domain users    60008 Feb  8 14:50 train-labels-idx1-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "# Check for your files in the unpacked dirs\n",
    "!ls -la $fmnist_unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metadata to Raw Data\n",
    "Wait, what have we actually downloaded, and are we actually allowed to **use** this data? We keep track of two key pieces of metadata along with a raw dataset:\n",
    "* Description (`DESCR`) Text: Human-readable text describing the dataset, its source, and what it represents\n",
    "* License (`LICENSE`) Text: Terms of use for this dataset, often in the form of a license agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, a dataset comes complete with its own README and LICENSE files. If these are available via URL, we can add these like we add any other data file, tagging them as metadata using the `name` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_url(\"http://www.cis.hut.fi/research/lvq_pak/README\",\n",
    "               file_name='lvq-pak.readme', name='DESCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:50:01,137 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:50:01,145 - fetch - DEBUG - Retrieved lvq-pak.readme (hash sha1:138b69cc0b4e02950cec5833752e50a54d36fd0f)\n",
      "2019-02-08 14:50:01,146 - datasets - DEBUG - Data Source lvq-pak is already unpacked. Skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/bus_number/data/interim/lvq-pak')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.fetch()\n",
    "dsrc.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/README',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'lvq-pak.readme'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now fetch 2 files. Note the metadata has been tagged accordingly in the `name` field\n",
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to dig a little deeper to find the license. we find it at the beginning of the README file contained within that distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\r\n",
      "*                                                                      *\r\n",
      "*                              LVQ_PAK                                 *\r\n",
      "*                                                                      *\r\n",
      "*                                The                                   *\r\n",
      "*                                                                      *\r\n",
      "*                   Learning  Vector  Quantization                     *\r\n",
      "*                                                                      *\r\n",
      "*                          Program  Package                            *\r\n",
      "*                                                                      *\r\n",
      "*                   Version 3.1 (April 7, 1995)                        *\r\n",
      "*                                                                      *\r\n",
      "*                          Prepared by the                             *\r\n",
      "*                    LVQ Programming Team of the                       *\r\n",
      "*                 Helsinki University of Technology                    *\r\n",
      "*           Laboratory of Computer and Information Science             *\r\n",
      "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\r\n",
      "*                              FINLAND                                 *\r\n",
      "*                                                                      *\r\n",
      "*                      Copyright (c) 1991-1995                         *\r\n",
      "*                                                                      *\r\n",
      "************************************************************************\r\n",
      "*                                                                      *\r\n",
      "*  NOTE: This program package is copyrighted in the sense that it      *\r\n",
      "*  may be used for scientific purposes. The package as a whole, or     *\r\n",
      "*  parts thereof, cannot be included or used in any commercial         *\r\n",
      "*  application without written permission granted by its producents.   *\r\n",
      "*  No programs contained in this package may be copied for commercial  *\r\n",
      "*  distribution.                                                       *\r\n",
      "*                                                                      *\r\n",
      "*  All comments concerning this program package may be sent to the     *\r\n",
      "*  e-mail address 'lvq@cochlea.hut.fi'.                                *\r\n",
      "*                                                                      *\r\n",
      "************************************************************************\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -35 $paths.interim_data_path/lvq-pak/lvq_pak-3.1/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than trying to be clever, let's just add the license metadata from a python string that we cut and paste from the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_txt = '''\n",
    "************************************************************************\n",
    "*                                                                      *\n",
    "*                              LVQ_PAK                                 *\n",
    "*                                                                      *\n",
    "*                                The                                   *\n",
    "*                                                                      *\n",
    "*                   Learning  Vector  Quantization                     *\n",
    "*                                                                      *\n",
    "*                          Program  Package                            *\n",
    "*                                                                      *\n",
    "*                   Version 3.1 (April 7, 1995)                        *\n",
    "*                                                                      *\n",
    "*                          Prepared by the                             *\n",
    "*                    LVQ Programming Team of the                       *\n",
    "*                 Helsinki University of Technology                    *\n",
    "*           Laboratory of Computer and Information Science             *\n",
    "*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\n",
    "*                              FINLAND                                 *\n",
    "*                                                                      *\n",
    "*                      Copyright (c) 1991-1995                         *\n",
    "*                                                                      *\n",
    "************************************************************************\n",
    "*                                                                      *\n",
    "*  NOTE: This program package is copyrighted in the sense that it      *\n",
    "*  may be used for scientific purposes. The package as a whole, or     *\n",
    "*  parts thereof, cannot be included or used in any commercial         *\n",
    "*  application without written permission granted by its producents.   *\n",
    "*  No programs contained in this package may be copied for commercial  *\n",
    "*  distribution.                                                       *\n",
    "*                                                                      *\n",
    "*  All comments concerning this program package may be sent to the     *\n",
    "*  e-mail address 'lvq@nucleus.hut.fi'.                                *\n",
    "*                                                                      *\n",
    "************************************************************************\n",
    "'''\n",
    "dsrc.add_metadata(contents=license_txt, kind='LICENSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, this will create a file, storing the creation instructions in the same `file_list` we use to store the URLs we wish to download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://www.cis.hut.fi/research/lvq_pak/lvq_pak-3.1.tar',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '86024a871724e521341da0ffb783956e39aadb6e',\n",
       "  'name': None,\n",
       "  'file_name': 'lvq_pak-3.1.tar'},\n",
       " {'url': 'http://www.cis.hut.fi/research/lvq_pak/README',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '138b69cc0b4e02950cec5833752e50a54d36fd0f',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'lvq-pak.readme'},\n",
       " {'contents': \"\\n************************************************************************\\n*                                                                      *\\n*                              LVQ_PAK                                 *\\n*                                                                      *\\n*                                The                                   *\\n*                                                                      *\\n*                   Learning  Vector  Quantization                     *\\n*                                                                      *\\n*                          Program  Package                            *\\n*                                                                      *\\n*                   Version 3.1 (April 7, 1995)                        *\\n*                                                                      *\\n*                          Prepared by the                             *\\n*                    LVQ Programming Team of the                       *\\n*                 Helsinki University of Technology                    *\\n*           Laboratory of Computer and Information Science             *\\n*                Rakentajanaukio 2 C, SF-02150 Espoo                   *\\n*                              FINLAND                                 *\\n*                                                                      *\\n*                      Copyright (c) 1991-1995                         *\\n*                                                                      *\\n************************************************************************\\n*                                                                      *\\n*  NOTE: This program package is copyrighted in the sense that it      *\\n*  may be used for scientific purposes. The package as a whole, or     *\\n*  parts thereof, cannot be included or used in any commercial         *\\n*  application without written permission granted by its producents.   *\\n*  No programs contained in this package may be copied for commercial  *\\n*  distribution.                                                       *\\n*                                                                      *\\n*  All comments concerning this program package may be sent to the     *\\n*  e-mail address 'lvq@nucleus.hut.fi'.                                *\\n*                                                                      *\\n************************************************************************\\n\",\n",
       "  'file_name': 'lvq-pak.license',\n",
       "  'name': 'LICENSE'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we fetch, the license file is created from this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:50:01,436 - fetch - DEBUG - lvq_pak-3.1.tar already exists and hash is valid\n",
      "2019-02-08 14:50:01,440 - fetch - DEBUG - lvq-pak.readme already exists and hash is valid\n",
      "2019-02-08 14:50:01,442 - fetch - DEBUG - Creating lvq-pak.license from `contents` string\n",
      "2019-02-08 14:50:01,456 - fetch - DEBUG - lvq-pak.license exists, but no hash to check. Setting to sha1:e5f53b172926d34cb6a49877be49ee08bc4d51c1\n",
      "2019-02-08 14:50:01,458 - datasets - DEBUG - Data Source lvq-pak is already unpacked. Skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/bus_number/data/interim/lvq-pak')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "dsrc.fetch(force=True)\n",
    "dsrc.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 30916\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:50 .\r\n",
      "drwxrwx--- 5 ava00125 domain users     4096 Oct 12 15:45 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users   747520 Feb  8 14:49 lvq_pak-3.1.tar\r\n",
      "-rw-rw---- 1 ava00125 domain users     2483 Feb  8 14:50 lvq-pak.license\r\n",
      "-rw-rw---- 1 ava00125 domain users     4958 Feb  8 14:50 lvq-pak.readme\r\n",
      "-rw-rw---- 1 ava00125 domain users  4422102 Feb  8 14:49 t10k-images-idx3-ubyte.gz\r\n",
      "-rw-rw---- 1 ava00125 domain users     5148 Feb  8 14:49 t10k-labels-idx1-ubyte.gz\r\n",
      "-rw-rw---- 1 ava00125 domain users 26421880 Feb  8 14:49 train-images-idx3-ubyte.gz\r\n",
      "-rw-rw---- 1 ava00125 domain users    29515 Feb  8 14:49 train-labels-idx1-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $paths.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Add metadata to F-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the link to the readme\n",
    "readme_url = 'https://github.com/zalandoresearch/fashion-mnist/blob/master/README.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidying up the readme to a nice useable format for this dataset\n",
    "fmnist_readme = '''\n",
    "Fashion-MNIST\n",
    "=============\n",
    "\n",
    "Notes\n",
    "-----\n",
    "Data Set Characteristics:\n",
    "    :Number of Instances: 70000\n",
    "    :Number of Attributes: 728\n",
    "    :Attribute Information: 28x28 8-bit greyscale image\n",
    "    :Missing Attribute Values: None\n",
    "    :Creator: Zalando\n",
    "    :Date: 2017\n",
    "\n",
    "This is a copy of Zalando's Fashion-MNIST [F-MNIST] dataset:\n",
    "https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images—consisting of a\n",
    "training set of 60,000 examples and a test set of 10,000\n",
    "examples. Each example is a 28x28 grayscale image, associated with a\n",
    "label from 10 classes. Fashion-MNIST is intended to serve as a direct\n",
    "drop-in replacement for the original [MNIST] dataset for benchmarking\n",
    "machine learning algorithms. It shares the same image size and\n",
    "structure of training and testing splits.\n",
    "\n",
    "References\n",
    "----------\n",
    "  - [F-MNIST] Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.\n",
    "    Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\n",
    "  - [MNIST] The MNIST Database of handwritten digits. Yann LeCun, Corinna Cortes,\n",
    "    Christopher J.C. Burges. http://yann.lecun.com/exdb/mnist/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the readme info as the DESCR\n",
    "fmnist.add_metadata(contents=fmnist_readme, kind='DESCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '8d4fb7e6c68d591d4c3dfef9ec88bf0d',\n",
       "  'name': 'train-images',\n",
       "  'file_name': 'train-images-idx3-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '25c81989df183df01b3e8a0aad5dffbe',\n",
       "  'name': 'train-labels',\n",
       "  'file_name': 'train-labels-idx1-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bef4ecab320f06d8554ea6380940ec79',\n",
       "  'name': 'test-images',\n",
       "  'file_name': 't10k-images-idx3-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bb300cfdad3c16e7a12a480ee83cd310',\n",
       "  'name': 'test-labels',\n",
       "  'file_name': 't10k-labels-idx1-ubyte.gz'},\n",
       " {'contents': \"\\nFashion-MNIST\\n=============\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 70000\\n    :Number of Attributes: 728\\n    :Attribute Information: 28x28 8-bit greyscale image\\n    :Missing Attribute Values: None\\n    :Creator: Zalando\\n    :Date: 2017\\n\\nThis is a copy of Zalando's Fashion-MNIST [F-MNIST] dataset:\\nhttps://github.com/zalandoresearch/fashion-mnist\\n\\nFashion-MNIST is a dataset of Zalando's article images—consisting of a\\ntraining set of 60,000 examples and a test set of 10,000\\nexamples. Each example is a 28x28 grayscale image, associated with a\\nlabel from 10 classes. Fashion-MNIST is intended to serve as a direct\\ndrop-in replacement for the original [MNIST] dataset for benchmarking\\nmachine learning algorithms. It shares the same image size and\\nstructure of training and testing splits.\\n\\nReferences\\n----------\\n  - [F-MNIST] Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.\\n    Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\\n  - [MNIST] The MNIST Database of handwritten digits. Yann LeCun, Corinna Cortes,\\n    Christopher J.C. Burges. http://yann.lecun.com/exdb/mnist/\\n\",\n",
       "  'file_name': 'fmnist.readme',\n",
       "  'name': 'DESCR'}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also find the LICENSE in the repo\n",
    "fmnist_license_url = 'https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist.add_url(url=fmnist_license_url, name='DESCR', file_name=\"fmnist.LICENSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:50:01,889 - fetch - DEBUG - train-images-idx3-ubyte.gz already exists and hash is valid\n",
      "2019-02-08 14:50:01,891 - fetch - DEBUG - train-labels-idx1-ubyte.gz already exists and hash is valid\n",
      "2019-02-08 14:50:01,904 - fetch - DEBUG - t10k-images-idx3-ubyte.gz already exists and hash is valid\n",
      "2019-02-08 14:50:01,905 - fetch - DEBUG - t10k-labels-idx1-ubyte.gz already exists and hash is valid\n",
      "2019-02-08 14:50:01,906 - fetch - DEBUG - Creating fmnist.readme from `contents` string\n",
      "2019-02-08 14:50:01,917 - fetch - DEBUG - fmnist.readme exists, but no hash to check. Setting to sha1:db57a3964b6b3515901f665412297aabf69e007e\n",
      "2019-02-08 14:50:02,280 - fetch - DEBUG - Retrieved fmnist.LICENSE (hash sha1:9cf1a09f827056b24769f829cdce9a349a635bb5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '8d4fb7e6c68d591d4c3dfef9ec88bf0d',\n",
       "  'name': 'train-images',\n",
       "  'file_name': 'train-images-idx3-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '25c81989df183df01b3e8a0aad5dffbe',\n",
       "  'name': 'train-labels',\n",
       "  'file_name': 'train-labels-idx1-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bef4ecab320f06d8554ea6380940ec79',\n",
       "  'name': 'test-images',\n",
       "  'file_name': 't10k-images-idx3-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bb300cfdad3c16e7a12a480ee83cd310',\n",
       "  'name': 'test-labels',\n",
       "  'file_name': 't10k-labels-idx1-ubyte.gz'},\n",
       " {'contents': \"\\nFashion-MNIST\\n=============\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 70000\\n    :Number of Attributes: 728\\n    :Attribute Information: 28x28 8-bit greyscale image\\n    :Missing Attribute Values: None\\n    :Creator: Zalando\\n    :Date: 2017\\n\\nThis is a copy of Zalando's Fashion-MNIST [F-MNIST] dataset:\\nhttps://github.com/zalandoresearch/fashion-mnist\\n\\nFashion-MNIST is a dataset of Zalando's article images—consisting of a\\ntraining set of 60,000 examples and a test set of 10,000\\nexamples. Each example is a 28x28 grayscale image, associated with a\\nlabel from 10 classes. Fashion-MNIST is intended to serve as a direct\\ndrop-in replacement for the original [MNIST] dataset for benchmarking\\nmachine learning algorithms. It shares the same image size and\\nstructure of training and testing splits.\\n\\nReferences\\n----------\\n  - [F-MNIST] Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.\\n    Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\\n  - [MNIST] The MNIST Database of handwritten digits. Yann LeCun, Corinna Cortes,\\n    Christopher J.C. Burges. http://yann.lecun.com/exdb/mnist/\\n\",\n",
       "  'file_name': 'fmnist.readme',\n",
       "  'name': 'DESCR',\n",
       "  'hash_value': 'db57a3964b6b3515901f665412297aabf69e007e'},\n",
       " {'url': 'https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '9cf1a09f827056b24769f829cdce9a349a635bb5',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'fmnist.LICENSE'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '8d4fb7e6c68d591d4c3dfef9ec88bf0d',\n",
       "  'name': 'train-images',\n",
       "  'file_name': 'train-images-idx3-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': '25c81989df183df01b3e8a0aad5dffbe',\n",
       "  'name': 'train-labels',\n",
       "  'file_name': 'train-labels-idx1-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bef4ecab320f06d8554ea6380940ec79',\n",
       "  'name': 'test-images',\n",
       "  'file_name': 't10k-images-idx3-ubyte.gz'},\n",
       " {'url': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
       "  'hash_type': 'md5',\n",
       "  'hash_value': 'bb300cfdad3c16e7a12a480ee83cd310',\n",
       "  'name': 'test-labels',\n",
       "  'file_name': 't10k-labels-idx1-ubyte.gz'},\n",
       " {'contents': \"\\nFashion-MNIST\\n=============\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 70000\\n    :Number of Attributes: 728\\n    :Attribute Information: 28x28 8-bit greyscale image\\n    :Missing Attribute Values: None\\n    :Creator: Zalando\\n    :Date: 2017\\n\\nThis is a copy of Zalando's Fashion-MNIST [F-MNIST] dataset:\\nhttps://github.com/zalandoresearch/fashion-mnist\\n\\nFashion-MNIST is a dataset of Zalando's article images—consisting of a\\ntraining set of 60,000 examples and a test set of 10,000\\nexamples. Each example is a 28x28 grayscale image, associated with a\\nlabel from 10 classes. Fashion-MNIST is intended to serve as a direct\\ndrop-in replacement for the original [MNIST] dataset for benchmarking\\nmachine learning algorithms. It shares the same image size and\\nstructure of training and testing splits.\\n\\nReferences\\n----------\\n  - [F-MNIST] Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.\\n    Han Xiao, Kashif Rasul, Roland Vollgraf. arXiv:1708.07747\\n  - [MNIST] The MNIST Database of handwritten digits. Yann LeCun, Corinna Cortes,\\n    Christopher J.C. Burges. http://yann.lecun.com/exdb/mnist/\\n\",\n",
       "  'file_name': 'fmnist.readme',\n",
       "  'name': 'DESCR',\n",
       "  'hash_value': 'db57a3964b6b3515901f665412297aabf69e007e'},\n",
       " {'url': 'https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE',\n",
       "  'hash_type': 'sha1',\n",
       "  'hash_value': '9cf1a09f827056b24769f829cdce9a349a635bb5',\n",
       "  'name': 'DESCR',\n",
       "  'file_name': 'fmnist.LICENSE'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-08 14:50:02,363 - datasets - DEBUG - Data Source fmnist is already unpacked. Skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ava00125/src/devel/bus_number/data/interim/fmnist')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmnist.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53812\r\n",
      "drwxrwx--- 2 ava00125 domain users     4096 Feb  8 14:05 .\r\n",
      "drwxrwx--- 6 ava00125 domain users     4096 Feb  8 12:29 ..\r\n",
      "-rw-rw---- 1 ava00125 domain users    62432 Feb  8 14:11 fmnist.LICENSE\r\n",
      "-rw-rw---- 1 ava00125 domain users     1144 Feb  8 14:11 fmnist.readme\r\n",
      "-rw-rw---- 1 ava00125 domain users    62425 Feb  8 14:07 LICENSE\r\n",
      "-rw-rw---- 1 ava00125 domain users  7840016 Feb  8 14:50 t10k-images-idx3-ubyte\r\n",
      "-rw-rw---- 1 ava00125 domain users    10008 Feb  8 14:50 t10k-labels-idx1-ubyte\r\n",
      "-rw-rw---- 1 ava00125 domain users 47040016 Feb  8 14:50 train-images-idx3-ubyte\r\n",
      "-rw-rw---- 1 ava00125 domain users    60008 Feb  8 14:50 train-labels-idx1-ubyte\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la $fmnist_unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Raw Data to the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmnist', 'lvq-pak']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_datasource(dsrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmnist', 'lvq-pak']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of this raw dataset catalog later in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Add F-MNIST to the Raw Dataset Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_datasource(fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fmnist', 'lvq-pak']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your fmnist dataset should now show up here:\n",
    "workflow.available_datasources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
